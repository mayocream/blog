---
title: Kong æºç åˆ†æ
date: "2021-09-21T04:30:00+08:00"
toc: true
lang: zh-Hans
typeface: sans
---

æœ¬æ–‡æœ€åˆäº 2020 å¹´ 9 æœˆåœ¨å…¬å¸å†…éƒ¨å‘è¡¨ï¼Œç°æ•´ç†å¹¶å¢åŠ éƒ¨åˆ†æ‰¹æ³¨å…¬å¼€å‘å¸ƒã€‚

æœ€å¼€å§‹åŠ å…¥å…¬å¸ Infrastructure å›¢é˜Ÿæ—¶ï¼Œè¿·èŒ«çš„æˆ‘æ¥åˆ°çš„çš„ä¸€ä¸ªä»»åŠ¡å°±æ˜¯å­¦ä¹  Lua å’Œ [OpenResty](https://github.com/openresty/lua-nginx-module)ï¼Œå½“æ—¶æ”¶åˆ°äº†ä¸¤æœ¬ä¹¦ç±çš„ PDF æ–‡ä»¶ï¼Œè¦æ±‚å°½å¿«ç†è§£å­¦ä¹ ï¼Œèƒ½å¤ŸæŒæ¡ [Kong](https://github.com/Kong/kong)ï¼Œå¹¶ä¸”å…·æœ‰ç ”å‘èƒ½åŠ›ã€‚

å½“æ—¶æˆ‘è¿˜æ²¡æœ‰æ€ä¹ˆæ¥è§¦å¼€æºç¤¾åŒºï¼Œèƒ½åŠ›åªåœç•™åœ¨ Git Cloneï¼Œå¤§æ¦‚èŠ±äº† 2 å‘¨æ—¶é—´ï¼Œæˆ‘å­¦ä¹  Lua åŸºæœ¬è¯­æ³•åï¼Œå¼€å§‹é˜…è¯» Kong é¡¹ç›®çš„æºç ï¼Œå¹¶æ‰¾åˆ°å‡ ä¸ªåˆ‡å…¥ç‚¹æ¢³ç†äº†æºç åˆ†ææ–‡æ¡£ï¼Œä¹Ÿåº”è¯¥æ­£æ˜¯è¿™ä¸ªæˆæœè®©ç»„é•¿è®¤åŒäº†æˆ‘ï¼Œè¿™ä¹‹åæˆ‘è´Ÿè´£å…¬å¸ API Gateway çš„å¼€å‘ï¼Œä»¥åŠç›¸å…³çš„è½åœ°å·¥ä½œã€‚

é‚£ä¹ˆæœ¬æ–‡é’ˆå¯¹ Kong çš„å¯åŠ¨æµç¨‹ã€æ’ä»¶æœºåˆ¶ã€ç¼“å­˜æœºåˆ¶å’Œè¯·æ±‚çš„ç”Ÿå‘½å‘¨æœŸåšäº†è¯¦ç»†çš„é˜è¿°ï¼Œä¸è¿‡ä»æœ‰æ¬ ç¼ºçš„æ˜¯ä»£ç†è½¬å‘åŠŸèƒ½ï¼Œä¾‹å¦‚è´Ÿè½½å‡è¡¡ã€å¥åº·æ£€æŸ¥ã€æœåŠ¡å‘ç°ç­‰ï¼Œä¸è¿‡ä»‹äºå½“æ—¶çš„æˆ‘è¿˜æ˜¯ä¸ªæ‡µæ‡‚çš„æ–°äººï¼Œè¿™é‡Œå°±å…ˆåŸè°…æˆ‘è‡ªå·±äº† ğŸ¾ã€‚

ç»§è¿™ç¯‡æ–‡ç« ä¹‹åï¼Œæˆ‘è¿˜æ’°å†™äº† Kong Ingress Controller æºç åˆ†æï¼Œåç»­è¿˜æœ‰ APISIX çš„æºç åˆ†æå“¦ã€‚

## 1. æ¦‚è¿°

æœ¬æ–‡é’ˆå¯¹çš„æ˜¯ Kong 2.1 ç‰ˆæœ¬ï¼ˆStableï¼‰ã€‚

æˆ‘é˜…è¯»å¹¶ä½œå‡ºä¸­æ–‡æ³¨é‡Šçš„ Commits å¯ä»¥åœ¨è¿™é‡Œçœ‹åˆ°ï¼š
[https://github.com/mayocream/kong/commits?author=mayocream](https://github.com/mayocream/kong/commits?author=huanghan39)

**Kongï¼ˆOpenRestyï¼‰çš„æ‰§è¡Œé˜¶æ®µ**ï¼š

![](images/openresty_phases.png)

Kong çš„æ’ä»¶æœºåˆ¶ä¹Ÿæ˜¯åŸºäº OpenResty çš„ç”Ÿå‘½å‘¨æœŸï¼Œåªä¸è¿‡æ˜¯å…¶åœ¨ä¸Šå±‚åšäº†äº›è®¸å°è£…ã€‚

**Kong çš„æ•°æ®åº“å…³è”å…³ç³»**ï¼š

![](images/kong_db.png)

Kong è™½ç„¶æ ‡ç§°è‡ªå·±æ˜¯ Cloud Native é¡¹ç›®[^kong]ï¼Œä¹Ÿä¸Šæ¦œäº† CNCF [å…¨æ™¯å›¾](https://landscape.cncf.io/)ï¼Œä½†æ˜¯å®ƒè¿˜ä¾èµ–äºä¼ ç»Ÿçš„æ•°æ®åº“ PostgreSQLï¼Œå¹¶ä¸”è¿˜è‡ªå®šä¹‰äº†è®¸å¤š functionï¼Œç›¸æ¯”äº APISIX èƒŒåå‚¨å­˜ Etcd è¦å¼±äº†è®¸å¤šã€‚æ¯”èµ· Etcd èƒ½å»ºç«‹ HTTP é•¿è¿æ¥ Watch æ•°æ®å˜åŒ–ï¼ŒKong åªèƒ½ä¾èµ–å®šæ—¶çš„è½®è¯¢ä»æ•°æ®åº“æ›´æ–°çŠ¶æ€ï¼Œæ•°æ®åº“é«˜å¯ç”¨ä¹Ÿç›¸æ¯” Etcd é›†ç¾¤è¦å¤æ‚å¾—å¤šã€‚

[^kong]: [ğŸ¦ The Cloud-Native API Gateway](https://github.com/Kong/kong)

## 2. é…ç½®æ–‡ä»¶

Kong åœ¨å¯åŠ¨é˜¶æ®µä¼šè§£æ [`kong/templates`](https://github.com/kong/kong/tree/master/kong/templates) ç›®å½•ä¸‹çš„ `.lua` æ¨¡æ¿æ–‡ä»¶ï¼Œæ³¨å…¥ç¯å¢ƒå˜é‡å’Œ `kong.conf` è¦†ç›–é…ç½®ï¼Œç”Ÿæˆ Nginx å¯åŠ¨çš„é…ç½®æ–‡ä»¶ `nginx.conf`ã€‚

ç»“æ„å¦‚ä¸‹ï¼š

```yaml
pid pids/nginx.pid;
error_log logs/error.log notice;

# injected nginx_main_* directives

env SKYWALKING_URL;

events {
    # injected nginx_events_* directives
    multi_accept on;
    worker_connections 16384;
}

http {
    lua_package_path       './?.lua;./?/init.lua;;;;';
    lua_package_cpath      ';;;';

    lua_shared_dict kong                        5m;
    lua_shared_dict kong_locks                  8m;
	...

    # injected nginx_http_* directives
    client_body_buffer_size 8k;

    init_by_lua_block {
        Kong = require 'kong'
        Kong.init()
    }

    init_worker_by_lua_block {
        Kong.init_worker()
    }

    upstream kong_upstream {
        server 0.0.0.1;

        # injected nginx_upstream_* directives

        balancer_by_lua_block {
            Kong.balancer()
        }
    }

	# Kong Proxy
    server {
        server_name kong;
		...
    }

	# Kong Admin API
    server {
        server_name kong_admin;
        ...
    }


}
```
Kong å®šä¹‰äº† `NGINX_MAIN_XXX`ï¼Œè¯¸å¦‚æ­¤ç±»çš„ç¯å¢ƒå˜é‡ï¼Œåœ¨è§£æé…ç½®é˜¶æ®µä¼šåŠ è½½åˆ° `nginx.conf` çš„æŒ‡å®šä½ç½®ï¼Œèƒ½å¤Ÿé¿å…ç›´æ¥ä¿®æ”¹æ¨¡æ¿æ–‡ä»¶ã€‚

ä¾‹å¦‚ï¼š

```bash
# åœ¨ main å—é‡Œå®šä¹‰ env å˜é‡
$ export NGINX_MAIN_ENV SKYWALKING_URL;
# åˆ›å»ºæ–°çš„ lua shared dict
$ export NGINX_HTTP_Lua_SHARED_DICT tracing_buffer 128m;
```

Kong [å®˜æ–¹çš„é…ç½®æ–‡æ¡£](https://docs.konghq.com/2.1.x/configuration/)å·²ç»éå¸¸è¯¦å°½ï¼Œè§£é‡Šäº†å„ä¸ªå‚æ•°ä»£è¡¨çš„å«ä¹‰ã€‚

è¿™é‡Œè¡¥å……ä¸€ç‚¹ï¼Œé€šå¸¸æˆ‘ä»¬éœ€è¦å®šä¹‰å¤šä¸ª Shared dictï¼Œé…ç½®å†™æ³•éœ€è¦æ”¹æˆè¿™ç§ä¸‘é™‹çš„å½¢å¼ï¼š
```
nginx_http_lua_shared_dict = cache_buffer_one 128m; lua_shared_dict cache_buffer_two 128m
```

## 3. åˆå§‹åŒ–

### 3.1. æ•°æ®åº“åˆå§‹åŒ–

`Kong.init()` æ–¹æ³•ä¸­åˆå§‹åŒ–æ•°æ®åº“ç›¸å…³ï¼š

```lua
  -- æ•°æ®åº“è¿æ¥ç›¸å…³
  local db = assert(DB.new(config))
  assert(db:init_connector())
  kong.db = db
```

`DB.new()` æ–¹æ³•ä¸­ä¾æ¬¡è°ƒç”¨äº† `Schema.new()`ã€`Entity.new()`ã€`DAO.new()` æ–¹æ³•ï¼Œä¸‹é¢ä¸€ä¸ªä¸ªæ¥è¯´æ˜ã€‚

#### 3.1.1. Schema

Kong çš„ Schema æ•°æ®ç»“æ„ä½“ä½äº `db/schema/entities` ä¸‹ï¼Œå°± `routes.lua` ä¸ºä¾‹ï¼š

```lua
local typedefs = require "kong.db.schema.typedefs"


return {
  name         = "routes",
  primary_key  = { "id" },
  endpoint_key = "name",
  workspaceable = true,
  subschema_key = "protocols",

  fields = {
    { id             = typedefs.uuid, },
    { created_at     = typedefs.auto_timestamp_s },
    { updated_at     = typedefs.auto_timestamp_s },
    { name           = typedefs.name },
    { protocols      = { type     = "set",
                         len_min  = 1,
                         required = true,
                         elements = typedefs.protocol,
                         mutually_exclusive_subsets = {
                           { "http", "https" },
                           { "tcp", "tls" },
                           { "grpc", "grpcs" },
                         },
                         default = { "http", "https" }, -- TODO: different default depending on service's scheme
                       }, },
    { methods        = typedefs.methods },
    { hosts          = typedefs.hosts },
    { paths          = typedefs.paths },
    { headers        = typedefs.headers },
    { https_redirect_status_code = { type = "integer",
                                     one_of = { 426, 301, 302, 307, 308 },
                                     default = 426, required = true,
                                   }, },
    { regex_priority = { type = "integer", default = 0 }, },
    { strip_path     = { type = "boolean", default = true }, },
    { path_handling  = { type = "string", default = "v0", one_of = { "v0", "v1" }, }, },
    { preserve_host  = { type = "boolean", default = false }, },
    { snis = { type = "set",
               elements = typedefs.sni }, },
    { sources = typedefs.sources },
    { destinations = typedefs.destinations },
    { tags             = typedefs.tags },
    { service = { type = "foreign", reference = "services" }, },
  },

  entity_checks = {
    { conditional = { if_field = "protocols",
                      if_match = { elements = { type = "string", not_one_of = { "grpcs", "https", "tls" }}},
                      then_field = "snis",
                      then_match = { len_eq = 0 },
                      then_err = "'snis' can only be set when 'protocols' is 'grpcs', 'https' or 'tls'",
                    }},
                  }
}

```

`primary_key` æ˜¯åœ¨æ•°æ®åº“ä¸­ä¸»é”®ä¹Ÿæ˜¯å½“ `cache_key` æœªå®šä¹‰æ—¶çš„é»˜è®¤ `cache_key`ã€‚

æœ‰ `type=foreign` çš„æƒ…å†µï¼Œentity åŠ è½½æ—¶ä¼šå½“ä½œ subschema åŠ è½½è¿›æ¥ã€‚

æ’ä»¶ä¸åŒäºå…¶ä»– entityï¼Œæœ‰ç‰¹å®š cache_keyã€‚

```lua
  name = "plugins",
  primary_key = { "id" },
  cache_key = { "name", "route", "service", "consumer" },
```

Cache ç›¸å…³æ“ä½œä¸­è°ƒç”¨ `Entity.cache_key()` è·å–ã€‚

```lua
    local cache_key = dao:cache_key(entity)
    local ok, err = cache:safe_set(cache_key, entity)
```

å…·ä½“ç”Ÿæˆ `cache_key` çš„æ–¹æ³•ï¼Œè¿”å›ä¸€ä¸ªå­—ç¬¦ä¸²ä½œä¸ºç¼“å­˜ keyã€‚

```lua
function DAO:cache_key(key, arg2, arg3, arg4, arg5, ws_id)

  if self.schema.workspaceable then
    ws_id = ws_id or workspaces.get_workspace_id()
  end

  -- Fast path: passing the cache_key/primary_key entries in
  -- order as arguments, this produces the same result as
  -- the generic code below, but building the cache key
  -- becomes a single string.format operation
  if type(key) == "string" then
    return fmt("%s:%s:%s:%s:%s:%s:%s", self.schema.name,
               key == nil and "" or key,
               arg2 == nil and "" or arg2,
               arg3 == nil and "" or arg3,
               arg4 == nil and "" or arg4,
               arg5 == nil and "" or arg5,
               ws_id == nil and "" or ws_id)
  end

  -- Generic path: build the cache key from the fields
  -- listed in cache_key or primary_key

  if type(key) ~= "table" then
    error("key must be a string or an entity table", 2)
  end

  if key.ws_id then
    ws_id = key.ws_id
  end

  local values = new_tab(7, 0)
  values[1] = self.schema.name
  local source = self.schema.cache_key or self.schema.primary_key

  local i = 2
  for _, name in ipairs(source) do
    local field = self.schema.fields[name]
    local value = key[name]
    if value == null or value == nil then
      value = ""
    elseif field.type == "foreign" then
      -- FIXME extract foreign key, do not assume `id`
      value = value.id
    end
    values[i] = tostring(value)
    i = i + 1
  end
  for n = i, 6 do
    values[n] = ""
  end

  values[7] = ws_id or ""

  return concat(values, ":")
end
```

`schema/init.lua` ä¸­å®šä¹‰äº† schema ç›¸å…³æ“ä½œçš„åŸºæœ¬æ–¹æ³•ï¼š

```lua
-- each_field() ç”¨äºéå† schema çš„ fields
-- æ˜¯ schema ç›¸å…³æ“ä½œæœ€é¢‘ç¹çš„
function Schema:each_field(values)
  local i = 1

  local subschema
  if values then
    subschema = get_subschema(self, values)
  end

  return function()
    local item = self.fields[i]
    if not item then
      return nil
    end
    local key = next(item)
    local field = resolve_field(self, key, item[key], subschema)
    i = i + 1
    return key, field
  end
end
```
`Schema.new()` æ–¹æ³•ä¸­é€šè¿‡å…ƒç»„è®¾ç½® `__index` è®©ç»“æ„ä½“ç»§æ‰¿ Schema ä¸‹å®šä¹‰çš„ä¸€ç³»åˆ—æ“ä½œæ–¹æ³•ã€‚
```lua
function Schema.new(definition, is_subschema)
  if not definition then
    return nil, validation_errors.SCHEMA_NO_DEFINITION
  end

  if not definition.fields then
    return nil, validation_errors.SCHEMA_NO_FIELDS
  end

  local self = copy(definition)

  -- ç»§æ‰¿ Schema ä¸‹å®šä¹‰çš„ä¸€ç³»åˆ—æ“ä½œæ–¹æ³•
  setmetatable(self, Schema)

  -- entity ç¼“å­˜çš„ cache_keyï¼Œ
  -- å¦‚æœæ²¡æœ‰è¿™ä¸ªå­—æ®µï¼Œåˆ™é»˜è®¤ä½¿ç”¨ schema å®šä¹‰çš„
  -- primary_key æ¥ä½œä¸º cache_key
  -- cache_key æ˜¯ä¸ªæ•°ç»„ï¼Œ
  -- è¿™é‡Œåªæ˜¯åˆ†å¼€å‚¨å­˜
  if self.cache_key then
    self.cache_key_set = {}
    for _, name in ipairs(self.cache_key) do
      self.cache_key_set[name] = true
    end
  end


  -- é€šè¿‡å…ƒç»„ __index æ–¹æ³•è°ƒç”¨ Schema:each_field() æ–¹æ³•
  -- éå† schema çš„ fields table
  for key, field in self:each_field() do
    -- Also give access to fields by name
    self.fields[key] = field
    if field.type == "record" and field.fields then
      allow_record_fields_by_name(field)
    end

    -- å¦‚æœæœ‰å¤–é”®
    -- åˆ™åŠ è½½å¤–é”®å…³è”çš„ schema è¿›æ¥
    if field.type == "foreign" then
      local err
      field.schema, err = get_foreign_schema_for_field(field)
      if not field.schema then
        return nil, err
      end

      if not is_subschema then
        -- Store the inverse relation for implementing constraints
        local constraints = assert(_cache[field.reference]).constraints
        table.insert(constraints, {
          schema     = self,
          field_name = key,
          on_delete  = field.on_delete,
        })
      end
    end
  end

  if self.workspaceable and self.name then
    if not _workspaceable[self.name] then
      _workspaceable[self.name] = true
      table.insert(_workspaceable, { schema = self })
    end
  end

  if self.name then
    -- do not reset the constraints list if a schema in reloaded
    if not _cache[self.name] then
      _cache[self.name] = {
        constraints = {},
      }
    end
    -- but always update the schema object in cache
    _cache[self.name].schema = self
  end

  return self
end
```
ç”¨äºä¸‹çº§ç»§æ‰¿çš„å…ƒç»„ï¼Œè™šæ™ƒä¸€æªã€‚
```lua
local Schema       = {}
Schema.__index     = Schema
```

#### 3.1.2. Entity

Entity åªæ˜¯ç®€å•å¯¹ Schema è¿›è¡Œä¸€å±‚å°è£…ã€‚

```lua
-- definition æ˜¯ schema ç»“æ„ä½“
function Entity.new(definition)

  -- åˆå§‹åŒ– Schema å¯¹è±¡
  local self, err = Schema.new(definition)
  if not self then
    return nil, err
  end

  -- éå† schema fields
  for name, field in self:each_field() do
    if field.nilable then
      return nil, entity_errors.NO_NILABLE:format(name)
    end

    if field.abstract then
      goto continue
    end

    if field.type == "map" then
      if field.keys.type ~= "string" then
        return nil, entity_errors.MAP_KEY_STRINGS_ONLY:format(name)
      end

    elseif field.type == "record" then
      make_records_required(field)

    elseif field.type == "function" then
      return nil, entity_errors.NO_FUNCTIONS:format(name)
    end

    ::continue::
  end

  self.new_subschema = Entity.new_subschema

  return self
end

```

Entity å¯¹è±¡éšåè¢«åŠ è½½åˆ° `DB.new()` å‡½æ•°ä¸­ï¼š

```lua
local schemas = {}

do
  -- load schemas
  -- core entities are for now the only source of schemas.
  -- TODO: support schemas from plugins entities as well.

  -- è½½å…¥æ ¸å¿ƒ entityï¼Œä¸ºä»€ä¹ˆæ˜¯æ ¸å¿ƒ entity
  -- å› ä¸ºè¿˜æœ‰ plugin è‡ªå®šä¹‰çš„ entity
  -- è¿™äº› entity æ˜¯ Kong è‡ªèº«çš„
  for _, entity_name in ipairs(constants.CORE_ENTITIES) do

    -- åŠ è½½ schemaï¼ˆæ•°æ®ç»“æ„ä½“ï¼‰
    local entity_schema = require("kong.db.schema.entities." .. entity_name)

    -- validate core entities schema via metaschema
    local ok, err_t = MetaSchema:validate(entity_schema)
    if not ok then
      return nil, fmt("schema of entity '%s' is invalid: %s", entity_name,
                      tostring(errors:schema_violation(err_t)))
    end

    -- åŠ è½½ entity å¯¹è±¡
    local entity, err = Entity.new(entity_schema)
    if not entity then
      return nil, fmt("schema of entity '%s' is invalid: %s", entity_name,
                      err)
    end
    schemas[entity_name] = entity

    -- load core entities subschemas
    local subschemas
    ok, subschemas = utils.load_module_if_exists("kong.db.schema.entities." .. entity_name .. "_subschemas")
    if ok then
      for name, subschema in pairs(subschemas) do
        local ok, err = entity:new_subschema(name, subschema)
        if not ok then
          return nil, ("error initializing schema for %s: %s"):format(entity_name, err)
        end
      end
    end
  end
end
```

#### 3.1.3. DAO

`db/dao/init.lua` ä¸­å®šä¹‰äº†ä¸€ç³»åˆ—å¯¹æ•°æ®åº“æ“ä½œçš„æ–¹æ³•ï¼Œä¾‹å¦‚ï¼š

```lua
function DAO:select(primary_key, options)
function DAO:page(size, offset, options)
function DAO:each(size, options)
function DAO:insert(entity, options)
function DAO:update(primary_key, entity, options)
function DAO:delete(primary_key, options)
...
```

`DAO.new()` ä¼šåˆ›å»ºä¸€ä¸ªåŒ…å« db è¿æ¥ä¿¡æ¯ï¼Œentity çš„ tableã€‚
```lua
-- schema å‚æ•°æ˜¯ Entity å¯¹è±¡
--  DB ç»“æ„ä½“ï¼š  local self   = {
  --    daos       = daos,       -- each of those has the connector singleton
  --    strategies = strategies,
  --    connector  = connector,
  --    strategy   = strategy,
  --    errors     = errors,
  --    infos      = connector:infos(),
  --    kong_config = kong_config,
  --  }
function _M.new(db, schema, strategy, errors)
  local fk_methods = generate_foreign_key_methods(schema)
  -- ç»§æ‰¿ DAO åŸºç¡€æ–¹æ³•
  local super      = setmetatable(fk_methods, DAO)

  local self = {
    db         = db,
    schema     = schema,
    strategy   = strategy,
    errors     = errors,
    pagination = utils.shallow_copy(defaults.pagination),
    super      = super,
  }

  if schema.dao then
    -- æ’ä»¶è‡ªå®šä¹‰çš„ dao
    local custom_dao = require(schema.dao)
    for name, method in pairs(custom_dao) do
      self[name] = method
    end
  end

  return setmetatable(self, { __index = super })
end
```

åœ¨ `db\init.lua` ä¸­åŠ è½½æ‰€æœ‰ DAO å¯¹è±¡ã€‚
```lua
  do
    -- load DAOs

    for _, schema in pairs(schemas) do
      local strategy = strategies[schema.name]
      if not strategy then
        return nil, fmt("no strategy found for schema '%s'", schema.name)
      end

      -- å‚¨å­˜ daos
      daos[schema.name] = DAO.new(self, schema, strategy, errors)
    end
  end
```
å’Œä¸Šé¢ç»“æ„ä¸€æ ·ï¼Œ`DB.new()` ä¸­æœ€åä¸º table è®¾ç½®å…ƒç»„ __index æ–¹æ³•ã€‚
```lua
  -- è®¾ç½®å…ƒç»„ __index æ–¹æ³•
  -- è®¿é—®ä¸å­˜åœ¨çš„å¯¹è±¡åˆ™å…ˆ
  -- DB.xxx å†è®¿é—® DB.daos.xxx
  return setmetatable(self, DB)


local DB = {}
DB.__index = function(self, k)
  -- rawget ä¸ºä¸è°ƒç”¨å…ƒç»„ __index æ–¹æ³•ï¼Œç›´æ¥è·å–åŸæ•°æ®
  return DB[k] or rawget(self, "daos")[k]
end
```
Kong ä¸­å…¶ä»–åœ°æ–¹è°ƒç”¨æ•°æ®åº“æ–¹æ³•ï¼Œæ“ä½œç¬¦ä¸º `kong.db.services:each_fields()`ï¼Œå³å®é™…è°ƒç”¨ `daos.services`ã€`entity:each_fields()`ï¼ˆå®é™…æ˜¯ `Schema:each_fields()`ï¼‰ã€‚

DAO ä¸‹é¢è¿˜æœ‰å°è£…çš„æ•°æ®åº“æ“ä½œå±‚ï¼Œä¾‹å¦‚ postgresql ç”Ÿæˆ SQL è¯­å¥çš„æ–¹æ³•ï¼Œè¿™é‡Œå°±ä¸èµ˜è¿°äº†ã€‚

DAO è¿™ä¸€å±‚ä¸€å±‚çš„å°è£…çœ‹å¾—æˆ‘æ˜¯çœŸçš„è„‘å£³ç—›ï¼ŒIDE è¿˜æ²¡æœ‰å¯¹ lua çš„æ™ºèƒ½æç¤ºï¼ŒæŒ‰ä½ Ctrl æ¯›éƒ½æ˜¾ç¤ºä¸å‡ºæ¥ã€‚

### 3.2. ç¼“å­˜æ„å»º

`init_by_lua`  é˜¶æ®µåˆå§‹åŒ– Master è¿›ç¨‹ï¼Œè¿›è¡Œè§£æé…ç½®æ–‡ä»¶ã€è¿æ¥æ•°æ®åº“ã€æ¸…ç©ºå…±äº«å†…å­˜ã€æ„å»ºè·¯ç”±ç¼“å­˜ç­‰æ“ä½œã€‚

`reset_kong_shm` ä»£ç å—é‡Œæ¸…ç†å…±äº«å†…å­˜ã€‚

```lua
    local shms = {
      "kong",
      "kong_locks",
      "kong_healthchecks",
      "kong_process_events",
      "kong_cluster_events",
      "kong_rate_limiting_counters",
      "kong_core_db_cache" .. suffix,
      "kong_core_db_cache_miss" .. suffix,
      "kong_db_cache" .. suffix,
      "kong_db_cache_miss" .. suffix,
      "kong_clustering",
    }

    for _, shm in ipairs(shms) do
      local dict = ngx.shared[shm]
      -- æ¸…ç©ºå…±äº«å†…å­˜
      if dict then
        dict:flush_all()
        dict:flush_expired(0)
      end
    end
```
#### 3.2.1. è·¯ç”±ç¼“å­˜

```lua
  else
    -- DB æ¨¡å¼
    local default_ws = db.workspaces:select_by_name("default")
    kong.default_workspace = default_ws and default_ws.id

    local ok, err = runloop.build_plugins_iterator("init")
    if not ok then
      error("error building initial plugins: " .. tostring(err))
    end

    -- åˆå§‹åŒ–è·¯ç”±
    -- æ„å»ºè·¯ç”±ç¼“å­˜
    assert(runloop.build_router("init"))
  end

  db:close()
end
```

DB æ¨¡å¼ä¸‹æœ€åä¸€æ­¥ä¼šè°ƒç”¨ `runloop.build_router("init")` æ„å»ºè·¯ç”±ç¼“å­˜ã€‚

æ„å»ºè·¯ç”±ç¼“å­˜è¿‡ç¨‹ä¸­ï¼Œåˆ¤æ–­ Kong æ˜¯å¦å·²ç»åˆå§‹åŒ–è¿‡ Cache ç»„ä»¶ï¼Œ`init` é˜¶æ®µæ²¡æœ‰å®Œæˆåˆå§‹åŒ– Cacheï¼Œåˆ™åˆ›å»ºä¸€ä¸ª Lua table ç¼“å­˜è·¯ç”±ä¿¡æ¯ã€‚`build_services_init_cache()` æ–¹æ³•ä¼šåˆ†é¡µåŠ è½½æ‰€æœ‰ Service åˆ° table ä¸­ï¼Œå¯¹å–å‡ºæ¥çš„ Servicesï¼Œåˆ¤æ–­å½“å‰ä½¿ç”¨çš„ Nginx æ¨¡å¼ï¼ˆhttp/streamï¼‰æ˜¯å¦å¯¹åº”è·¯ç”±æŒ‡å®šçš„åè®®ï¼Œå¯¹åº”åˆ™å–å‡º Service å¯¹è±¡ï¼Œä¸ Route è¿›è¡Œå…³è”ã€‚æœ€åä¼ é€’ç»™ `Router.new()` æ–¹æ³•é€šè¿‡ç®—æ³•å»ºç«‹æ ‘å½¢ç»“æ„å»ºç«‹è·¯ç”±ç´¢å¼•ã€‚

Kong åŸºäº Nginx Subsystem æ”¯æŒçš„åè®®å¯¹åº”å…³ç³»ï¼š

- http/https -> http
- grpc/grpcs -> http
- tcp/tls -> stream

```lua
  build_router = function(version)
    local db = kong.db
    -- table å‚¨å­˜æ‰€æœ‰çš„ route-service æ•°æ®
    local routes, i = {}, 0

    local err
    -- The router is initially created on init phase, where kong.core_cache is
    -- still not ready. For those cases, use a plain Lua table as a cache
    -- instead
    -- init é˜¶æ®µ core_cache è¿˜æ²¡æœ‰åˆå§‹åŒ–å®Œæˆ
    -- è¿™é‡Œä½¿ç”¨ table å‚¨å­˜
    local services_init_cache = {}
    if not kong.core_cache and db.strategy ~= "off" then
      -- è·å–æ‰€æœ‰çš„ servicesï¼Œä½¿ç”¨é»˜è®¤çš„åˆ†é¡µå‚æ•°
      services_init_cache, err = build_services_init_cache(db)
      if err then
        services_init_cache = {}
        log(WARN, "could not build services init cache: ", err)
      end
    end

    local counter = 0
    local page_size = db.routes.pagination.page_size
    for route, err in db.routes:each(nil, GLOBAL_QUERY_OPTS) do
      if err then
        return nil, "could not load routes: " .. err
      end

      -- æ£€æŸ¥ router æ•°æ®æ˜¯å¦å·²ç»å˜åŒ–
      -- é€šè¿‡æ£€æŸ¥ router hash æ˜¯å¦ä¸€è‡´åˆ¤æ–­
      -- å¦‚æœå·²ç»å˜åŒ–åˆ™é€€å‡ºå‡½æ•°
      if db.strategy ~= "off" then
        if kong.core_cache and counter > 0 and counter % page_size == 0 then
          local new_version, err = get_router_version()
          if err then
            return nil, "failed to retrieve router version: " .. err
          end

          if new_version ~= version then
            return nil, "router was changed while rebuilding it"
          end
        end
      end

      -- subsystem æ˜¯å¦æ”¯æŒå½“å‰è·¯ç”±çš„åè®®
      if should_process_route(route) then
        -- è·å– route çš„ service
        local service, err = get_service_for_route(db, route, services_init_cache)
        if err then
          return nil, err
        end

        local r = {
          route   = route,
          service = service,
        }

        i = i + 1
        -- å‚¨å­˜æ‰€æœ‰çš„ route-service
        routes[i] = r
      end

      counter = counter + 1
    end

    local new_router, err = Router.new(routes)
    if not new_router then
      return nil, "could not create router: " .. err
    end

    -- router å®ä¾‹
    router = new_router

    if version then
      router_version = version
    end

    -- LEGACY - singletons module is deprecated
    singletons.router = router
    -- /LEGACY

    return true
  end
```

æ„å»ºè·¯ç”±ç¼“å­˜è¿‡ç¨‹ä¸­ï¼Œåˆ¤æ–­ Kong æ˜¯å¦å·²ç»åˆå§‹åŒ–è¿‡ Cache ç»„ä»¶ï¼Œ`init` é˜¶æ®µæ²¡æœ‰å®Œæˆåˆå§‹åŒ– Cacheï¼Œåˆ™åˆ›å»ºä¸€ä¸ª Lua table ç¼“å­˜ servicesã€‚

```lua
  -- ä»¥ [service.id] = service
  -- ç»“æ„å‚¨å­˜åˆ° table ä¸­
  local function build_services_init_cache(db)
    local services_init_cache = {}

    for service, err in db.services:each(nil, GLOBAL_QUERY_OPTS) do
      if err then
        return nil, err
      end

      services_init_cache[service.id] = service
    end

    return services_init_cache
  end
```

`build_services_init_cache(db)` æ–¹æ³•ï¼Œè°ƒç”¨ `DAO:each()` å‡½æ•°ï¼Œä½¿ç”¨é»˜è®¤åˆ†é¡µå‚æ•° `page_size=1000`ï¼Œè¿›è¡Œåˆ†é¡µè·å–ï¼Œå†è¿”å›å¯è¿­ä»£çš„å•æ¡è®°å½•ã€‚è¿™é‡Œå› ä¸º `init_by_lua` é˜¶æ®µæ²¡æœ‰åˆå§‹åŒ–ç¼“å­˜ï¼ˆ`kong.core_cache` ï¼‰ï¼Œæ‰€ä»¥ä½¿ç”¨ Lua table å‚¨å­˜ç¼“å­˜æ•°æ®ã€‚

```lua
function DAO:each(size, options)
  if size ~= nil then
    validate_size_type(size)
  end

  -- è·å–åˆ†é¡µæ¡ä»¶ï¼Œæœ‰é»˜è®¤å€¼
  options = get_pagination_options(self, options)

  if size ~= nil then
    local ok, err = validate_size_value(size, options.pagination.max_page_size)
    if not ok then
      local err_t = self.errors:invalid_size(err)
      return nil, tostring(err_t), err_t
    end

  else
    size = options.pagination.page_size
  end

  local ok, errors = validate_options_value(self, options)
  if not ok then
    local err_t = self.errors:invalid_options(errors)
    return nil, tostring(err_t), err_t
  end

  local pager = function(size, offset, options)
    return self.strategy:page(size, offset, options)
  end

  return iteration.by_row(self, pager, size, options)
end
```

é»˜è®¤åˆ†é¡µå‚æ•°åœ¨ `db/strategies/connector.lua` æ–‡ä»¶ä¸­ï¼š

```lua
local Connector = {
  defaults = {
    -- é»˜è®¤åˆ†é¡µæ¡ä»¶
    pagination = {
      page_size     = 1000,
      max_page_size = 50000,
    },
  },
}
```

æ¥ä¸‹æ¥ä¼šéå†æ‰€æœ‰çš„ Routesï¼Œé€ä¸ªè°ƒç”¨ `should_process_route()` å’Œ `get_service_for_route()` æ–¹æ³•ï¼Œå‰è€…ä¼šåˆ¤æ–­ Nginx Subsystem æ˜¯å¦å’Œ Route åè®®ä¸€è‡´ï¼Œåè€…å…ˆåœ¨ç¼“å­˜ä¸­æŸ¥æ‰¾ Serviceï¼Œå¦‚æœç¼“å­˜ä¸­ä¸å­˜åœ¨åˆ™ä»æ•°æ®åº“ä¸­è·å–ã€‚

```lua
  local function get_service_for_route(db, route, services_init_cache)
    -- route å…³è”çš„ service å¤–é”®
    local service_pk = route.service
    if not service_pk then
      return nil
    end

    -- æŸ¥æ‰¾ç¼“å­˜ table é‡Œçš„ service
    local id = service_pk.id
    local service = services_init_cache[id]
    if service then
      return service
    end

    local err

    -- kong.core_cache is available, not in init phase
    if kong.core_cache then
      -- é€šè¿‡ mlcache æŸ¥è¯¢ service
      local cache_key = db.services:cache_key(service_pk.id, nil, nil, nil, nil,
                                              route.ws_id)
      -- æŸ¥è¯¢ cache è·å–ï¼Œæ²¡æœ‰è·å–åˆ°åˆ™è°ƒç”¨ load_service_from_db è·å–
      service, err = kong.core_cache:get(cache_key, TTL_ZERO,
                                    load_service_from_db, service_pk)

    else -- init phase, kong.core_cache not available

      -- A new service/route has been inserted while the initial route
      -- was being created, on init (perhaps by a different Kong node).
      -- Load the service individually and update services_init_cache with it
      -- ç›´æ¥æŸ¥è¯¢æ•°æ®åº“è·å– service
      service, err = load_service_from_db(service_pk)
      services_init_cache[id] = service
    end

    if err then
      return nil, "error raised while finding service for route (" .. route.id .. "): " ..
                  err

    elseif not service then
      return nil, "could not find service for route (" .. route.id .. ")"
    end


    -- TODO: this should not be needed as the schema should check it already
    if SUBSYSTEMS[service.protocol] ~= subsystem then
      log(WARN, "service with protocol '", service.protocol,
                "' cannot be used with '", subsystem, "' subsystem")

      return nil
    end

    return service
  end

```

`load_service_from_db()` æ–¹æ³•ä¸­åªæ˜¯ç®€å•è°ƒç”¨ `DAO:select()` æ–¹æ³•ï¼Œå–å‡º Service åŒæ—¶ç¼“å­˜åˆ° `services_init_cache` table ä¸­ï¼Œä¸æ›´æ–° `Kong.core_cache` ç»„ä»¶ã€‚

å¯¹æ•°æ®åº“å®ä½“å¯¹è±¡çš„å¤„ç†ä¸­ï¼Œåªæœ‰`create` ã€`update`ã€`delete` ä¼šé€šè¿‡äº‹ä»¶å¹¿æ’­åˆ°å…¶ä»– Worker åŒæ­¥ï¼Œåé¢äº‹ä»¶çš„ä¸€èŠ‚æˆ‘ä»¬ä¼šè¯¦ç»†é˜è¿°ã€‚

æ¥ä¸‹æ¥å°† `{router, service}` æ•°ç»„ä¼ å…¥ `router.iua` ä¸­ `Router.new()` å‡½æ•°å¤„ç†ã€‚

```lua
local new_router, err = Router.new(routes)
if not new_router then
    return nil, "could not create router: " .. err
end

-- ç»‘å®š router å®ä¾‹
router = new_router
```

å…·ä½“æ„å»ºè·¯ç”±ç´¢å¼•çš„è¿‡ç¨‹åœ¨ `router.lua` ä¸­çš„ `_M.new(routes)` å‡½æ•°ï¼Œä½¿ç”¨ **[lua-resty-lrucache](https://github.com/openresty/lua-resty-lrucache)** åŒ…ç¼“å­˜ï¼Œå¯¹è·¯ç”±å’Œ Service ç»„åˆé€šè¿‡ç®—æ³•è¿›è¡Œæ’åºï¼Œæ„å»ºç´¢å¼•ï¼Œå°†è¯¸å¦‚ `{cache_key: {route, service}}` ç»“æ„å­˜å…¥ç¼“å­˜ä¸­ï¼Œè¿”å› Router å®ä¾‹ã€‚

è·¯ç”±ç´¢å¼• Key çš„æ„å»ºæ–¹æ³•ï¼š

```lua
    local cache_key = req_method .. "|" .. req_uri .. "|" .. req_host ..
                      "|" .. ctx.src_ip .. "|" .. ctx.src_port ..
                      "|" .. ctx.dst_ip .. "|" .. ctx.dst_port ..
                      "|" .. ctx.sni
```

Router å®ä¾‹ç”± Master è¿›ç¨‹æ„å»ºï¼Œå¹¶ fork åˆ°å„ä¸ª Worker è¿›ç¨‹ä½¿ç”¨ã€‚

Worker æ‰§è¡Œå®Œå…±äº«å†…å­˜çš„æ„å»ºåï¼Œæ³¨å†Œå®šæ—¶ä»»åŠ¡ï¼Œå®šæ—¶é‡å»ºç¼“å­˜ã€‚

```lua
      -- å®šæ—¶é‡å»ºè·¯ç”±ç¼“å­˜
      if kong.db.strategy ~= "off" then
        timer_every(worker_state_update_frequency, function(premature)
          if premature then
            return
          end

          -- Don't wait for the semaphore (timeout = 0) when updating via the
          -- timer.
          -- If the semaphore is locked, that means that the rebuild is
          -- already ongoing.
          local ok, err = rebuild_router(ROUTER_ASYNC_OPTS)
          if not ok then
            log(ERR, "could not rebuild router via timer: ", err)
          end
        end)

        timer_every(worker_state_update_frequency, function(premature)
          if premature then
            return
          end

          local ok, err = rebuild_plugins_iterator(PLUGINS_ITERATOR_ASYNC_OPTS)
          if not ok then
            log(ERR, "could not rebuild plugins iterator via timer: ", err)
          end
        end)
      end
```

#### 3.2.2. Entity ç¼“å­˜

è¿™é‡Œé¦–å…ˆä»‹ç»ä¸€ä¸‹ **[lua-resty-mlcache](https://github.com/thibaultcha/lua-resty-mlcache)** è¿™ä¸ªç¼“å­˜åº“ï¼Œè¯¥åº“åŸºäº [lua_shared_dict](https://github.com/openresty/lua-nginx-module#lua_shared_dict) å’Œ [lua-resty-lrucache](https://github.com/openresty/lua-resty-lrucache) åšäº†ä¸¤å±‚ç¼“å­˜ï¼ŒWorker ä¼šæœ‰è‡ªå·±çš„è¿›ç¨‹çº§åˆ«çš„ LRU ç¼“å­˜ï¼Œé¦–å…ˆä¼šåœ¨è¿™ä¸€å±‚è¿›è¡ŒæŸ¥è¯¢ï¼Œå…¶æ¬¡ä½¿ç”¨å…±äº«å†…å­˜è¿›è¡Œç¼“å­˜ï¼Œæœ€åæä¾› callback ä»æ•°æ®åº“æŸ¥è¯¢ï¼Œä½¿ç”¨ [lua-resty-lock](https://github.com/openresty/lua-resty-lock) åº“åˆ›å»ºé”åªå…è®¸å•ä¸ªè¿›ç¨‹æ‰§è¡Œ callbackã€‚

mlcache æ¶æ„å›¾ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Nginx                                           â”‚
â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚       â”‚worker     â”‚ â”‚worker     â”‚ â”‚worker     â”‚ â”‚
â”‚ L1    â”‚           â”‚ â”‚           â”‚ â”‚           â”‚ â”‚
â”‚       â”‚ Lua cache â”‚ â”‚ Lua cache â”‚ â”‚ Lua cache â”‚ â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚             â”‚             â”‚             â”‚       â”‚
â”‚             â–¼             â–¼             â–¼       â”‚
â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚       â”‚                                       â”‚ â”‚
â”‚ L2    â”‚           lua_shared_dict             â”‚ â”‚
â”‚       â”‚                                       â”‚ â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                           â”‚ mutex               â”‚
â”‚                           â–¼                     â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚                  â”‚     callback     â”‚           â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
  L3                        â”‚   I/O fetch
                            â–¼

                   Database, API, DNS, Disk, any I/O...
```

`Kong.init_worker()` ä¸­è¿›è¡Œåˆå§‹åŒ–ç¼“å­˜ï¼š

```lua
  -- åˆå§‹åŒ–åŸºäºå…±äº«å†…å­˜çš„ cache
  local cache, err = kong_global.init_cache(kong.configuration, cluster_events, worker_events)
  if not cache then
    stash_init_worker_error("failed to instantiate 'kong.cache' module: " ..
                            err)
    return
  end
  kong.cache = cache

  local core_cache, err = kong_global.init_core_cache(kong.configuration, cluster_events, worker_events)
  if not core_cache then
    stash_init_worker_error("failed to instantiate 'kong.core_cache' module: " ..
                            err)
    return
  end
  kong.core_cache = core_cache

  ok, err = runloop.set_init_versions_in_cache()
  if not ok then
    stash_init_worker_error(err) -- 'err' fully formatted
    return
  end
```

`global.init_cache()` ç»“æ„å¦‚ä¸‹ï¼š

```lua
function _GLOBAL.init_cache(kong_config, cluster_events, worker_events)
  local db_cache_ttl = kong_config.db_cache_ttl
  local db_cache_neg_ttl = kong_config.db_cache_neg_ttl
  local cache_pages = 1
  if kong_config.database == "off" then
    db_cache_ttl = 0
    db_cache_neg_ttl = 0
    cache_pages = 2
  end

  return kong_cache.new {
    shm_name          = "kong_db_cache",
    cluster_events    = cluster_events,
    worker_events     = worker_events,
    ttl               = db_cache_ttl,
    neg_ttl           = db_cache_neg_ttl or db_cache_ttl,
    resurrect_ttl     = kong_config.resurrect_ttl,
    cache_pages       = cache_pages,
    resty_lock_opts   = {
      exptime = 10,
      timeout = 5,
    },
  }
end
```

æœ€ç»ˆä¼šè°ƒç”¨ `cache.lua` ä¸­ `_M.new()` è¿›è¡Œå¿…è¦å‚æ•°çš„éªŒè¯ï¼Œæ£€æµ‹å…±äº«å†…å­˜å—æ˜¯å¦å¯ä»¥è®¿é—®ï¼Œå…³è”é›†ç¾¤äº‹ä»¶å’Œ Worker äº‹ä»¶ï¼Œå®šä¹‰åºåˆ—åŒ–å’Œååºåˆ—åŒ–çš„æ–¹æ³•ï¼Œå¯¹ mlcache è¿›è¡Œä¸€å±‚å°è£…ã€‚

```lua
function _M.new(opts)
  -- opts validation

  opts = opts or {}

  local mlcaches = {}
  local shm_names = {}

  for i = 1, opts.cache_pages or 1 do
    local channel_name  = (i == 1) and "mlcache"                 or "mlcache_2"
    local shm_name      = (i == 1) and opts.shm_name             or opts.shm_name .. "_2"
    local shm_miss_name = (i == 1) and opts.shm_name .. "_miss"  or opts.shm_name .. "_miss_2"

    if ngx.shared[shm_name] then
      local mlcache, err = resty_mlcache.new(shm_name, shm_name, {
        shm_miss         = shm_miss_name,
        shm_locks        = "kong_locks",
        shm_set_retries  = 3,
        lru_size         = LRU_SIZE,
        ttl              = max(opts.ttl     or 3600, 0),
        neg_ttl          = max(opts.neg_ttl or 300,  0),
        resurrect_ttl    = opts.resurrect_ttl or 30,
        resty_lock_opts  = opts.resty_lock_opts,
        ipc = { -- è¿›ç¨‹é—´é€šä¿¡çš„å‡½æ•°ç»‘å®š
          register_listeners = function(events)
            for _, event_t in pairs(events) do
              opts.worker_events.register(function(data)
                event_t.handler(data)
              end, channel_name, event_t.channel)
            end
          end,
          broadcast = function(channel, data)
            local ok, err = opts.worker_events.post(channel_name, channel, data)
            if not ok then
              log(ERR, "failed to post event '", channel_name, "', '",
                       channel, "': ", err)
            end
          end
        }
      })
      if not mlcache then
        return nil, "failed to instantiate mlcache: " .. err
      end
      mlcaches[i] = mlcache
      shm_names[i] = shm_name
    end
  end

  local curr_mlcache = 1

  if opts.cache_pages == 2 then
    curr_mlcache = ngx.shared.kong:get("kong:cache:" .. opts.shm_name .. ":curr_mlcache") or 1
  end

  local self          = {
    cluster_events    = opts.cluster_events,
    mlcache           = mlcaches[curr_mlcache],
    mlcaches          = mlcaches,
    shm_names         = shm_names,
    curr_mlcache      = curr_mlcache,
  }

  local ok, err = self.cluster_events:subscribe("invalidations", function(key)
    log(DEBUG, "received invalidate event from cluster for key: '", key, "'")
    self:invalidate_local(key)
  end)
  if not ok then
    return nil, "failed to subscribe to invalidations cluster events " ..
                "channel: " .. err
  end

  _init[opts.shm_name] = true

  return setmetatable(self, mt)
end
```

åˆå§‹åŒ–å®Œç¼“å­˜æ¨¡å—åï¼ŒWorker ä¼šæ ¹æ®é…ç½®æ–‡ä»¶ä¸­çš„ `db_cache_warmup_entities` åŠ è½½æŒ‡å®šçš„æ•°æ®åº“èµ„æºåˆ°å†…å­˜è¿›è¡Œç¼“å­˜ï¼Œé»˜è®¤é…ç½®ä¼šç¼“å­˜ `services, plugins`ã€‚

`LRU_SIZE` å€¼ä¸º 500,000ï¼Œå•ä½æ˜¯ itemï¼Œè®¾ç½®æœ€å¤§èƒ½å‚¨å­˜çš„ item æ•°é‡ï¼Œè¿™ä¸ªå€¼è¡¨ç¤ºå•ä¸ª Worker LRU Cache æœ€å¤§å ç”¨ 500M å†…å­˜ã€‚

Worker ä¼šæ ¹æ®é…ç½®é¡¹åŠ è½½æ•°æ®åº“å®ä½“åˆ°å…±äº«å†…å­˜ç¼“å­˜ã€‚

```lua
local function execute_cache_warmup(kong_config)
  if kong_config.database == "off" then
    return true
  end

  -- åªåœ¨ä¸€ä¸ª worker ä¸Šæ‰§è¡Œæ“ä½œ
  -- åŠ è½½æ•°æ®åº“å®ä½“åˆ°å…±äº«å†…å­˜ç¼“å­˜
  if ngx.worker.id() == 0 then
    local ok, err = cache_warmup.execute(kong_config.db_cache_warmup_entities)
    if not ok then
      return nil, err
    end
  end

  return true
end
```
è¿™é‡Œåªåœ¨ä¸€ä¸ª Worker è¿›ç¨‹ä¸ŠåŠ è½½æ•°æ®åº“æ•°æ®ï¼ŒéšååŒæ­¥åˆ°å…¶ä»–çš„ Worker ä¸Šã€‚

`cache_warmup.execute()` é‡ŒåšåŸºæœ¬ä¿¡æ¯çš„æ£€æµ‹ï¼Œéšåè°ƒç”¨ `cache_warmup_single_entity(dao)` æ–¹æ³•ã€‚

```lua
-- åŠ è½½æ•°æ®åº“å®ä½“åˆ°ç¼“å­˜ï¼Œä»¥å®ç°æ›´å¿«çš„è®¿é—®é€Ÿåº¦
-- åœ¨ Worker åˆå§‹åŒ–é˜¶æ®µè¿è¡Œ
-- é»˜è®¤åŠ è½½ service, plugins
-- å¤§å°å—é…ç½® mem_cache_size å½±å“
-- Loads entities from the database into the cache, for rapid subsequent
-- access. This function is intented to be used during worker initialization.
function cache_warmup.execute(entities)
  if not kong.cache or not kong.core_cache then
    return true
  end

  for _, entity_name in ipairs(entities) do
    if entity_name == "routes" then
      -- do not spend shm memory by caching individual Routes entries
      -- because the routes are kept in-memory by building the router object
      kong.log.notice("the 'routes' entry is ignored in the list of ",
                      "'db_cache_warmup_entities' because Kong ",
                      "caches routes in memory separately")
      goto continue
    end

    local dao = kong.db[entity_name]
    if not (type(dao) == "table" and dao.schema) then
      kong.log.warn(entity_name, " is not a valid entity name, please check ",
                    "the value of 'db_cache_warmup_entities'")
      goto continue
    end

    local ok, err = cache_warmup_single_entity(dao)
    if not ok then
      if err == "no memory" then
        kong.log.warn("cache warmup has been stopped because cache ",
                      "memory is exhausted, please consider increasing ",
                      "the value of 'mem_cache_size' (currently at ",
                      kong.configuration.mem_cache_size, ")")

        return true
      end
      return nil, err
    end

    ::continue::
  end

  return true
end
```

ä¸ç¼“å­˜ Routesï¼Œå› ä¸º Route å·²ç»åœ¨ä¸Šä¸€èŠ‚ä¸­æ„å»ºä¸ºè·¯ç”±ç´¢å¼•æ ‘ï¼Œé€šè¿‡ fork åˆ°æ‰€æœ‰çš„ Worker å†…å­˜é‡Œäº†ã€‚

```lua
local function cache_warmup_single_entity(dao)
  local entity_name = dao.schema.name

  -- é€‰å®šå‚¨å­˜åœ°æ–¹ cache/core_cache
  local cache_store = constants.ENTITY_CACHE_STORE[entity_name]
  -- cache å…¨å±€å¯¹è±¡
  local cache = kong[cache_store]

  ngx.log(ngx.NOTICE, "Preloading '", entity_name, "' into the ", cache_store, "...")

  local start = ngx.now()

  local hosts_array, hosts_set, host_count
  if entity_name == "services" then
    hosts_array = {}
    hosts_set = {}
    host_count = 0
  end

  for entity, err in dao:each(nil, GLOBAL_QUERY_OPTS) do
    if err then
      return nil, err
    end

    if entity_name == "services" then
      if utils.hostname_type(entity.host) == "name"
         and hosts_set[entity.host] == nil then
        host_count = host_count + 1
        hosts_array[host_count] = entity.host
        hosts_set[entity.host] = true
      end
    end

    -- è·å– cache_key
    local cache_key = dao:cache_key(entity)

    -- è°ƒç”¨ mlcache çš„ safe_set æ–¹æ³•ï¼Œ
    -- å†…å­˜ä¸è¶³ä¼šæŠ¥é”™
    local ok, err = cache:safe_set(cache_key, entity)
    if not ok then
      return nil, err
    end
  end

  if entity_name == "services" and host_count > 0 then
    ngx.timer.at(0, warmup_dns, hosts_array, host_count)
  end

  local elapsed = math.floor((ngx.now() - start) * 1000)

  ngx.log(ngx.NOTICE, "finished preloading '", entity_name,
                      "' into the ", cache_store, " (in ", tostring(elapsed), "ms)")
  return true
end
```

`cache_warmup_single_entity()` ä¼šåŠ è½½è¯¥ dao æ‰€æœ‰çš„æ•°æ®åˆ°å†…å­˜ä¸­ï¼Œ`set` æ–¹æ³•ä¼šåˆ†å‘äº‹ä»¶åŒæ­¥æ•°æ®åˆ°å…¶ä»–çš„ Worker ä¸Šï¼Œæœ€ç»ˆæ¯ä¸ª Worker éƒ½ä¼šç¼“å­˜ä¸€ä»½ã€‚

### 3.3. äº‹ä»¶è®¢é˜…

`Kong.init_worker()` ä¸­åˆå§‹åŒ– Worker äº‹ä»¶å’Œé›†ç¾¤äº‹ä»¶ã€‚

```lua
  local worker_events, err = kong_global.init_worker_events()
  if not worker_events then
    stash_init_worker_error("failed to instantiate 'kong.worker_events' " ..
                            "module: " .. err)
    return
  end
  kong.worker_events = worker_events

  local cluster_events, err = kong_global.init_cluster_events(kong.configuration, kong.db)
  if not cluster_events then
    stash_init_worker_error("failed to instantiate 'kong.cluster_events' " ..
                            "module: " .. err)
    return
  end
  kong.cluster_events = cluster_events
```

Worker äº‹ä»¶å†…éƒ¨æ˜¯ä½¿ç”¨ **[lua-resty-worker-events](https://github.com/Kong/lua-resty-worker-events)** åº“å®ç°çš„è¿›ç¨‹é—´äº‹ä»¶å¤„ç†ï¼ŒåŸç†æ˜¯é€šè¿‡å…±äº«å†…å­˜å‚¨å­˜äº‹ä»¶ï¼Œæ¯ç§’æ‹‰å–å…±äº«å†…å­˜ä¸­çš„äº‹ä»¶ï¼Œè¿›è¡Œå¤„ç†ã€‚

```lua
function _GLOBAL.init_worker_events()
  -- Note: worker_events will not work correctly if required at the top of the file.
  --       It must be required right here, inside the init function
  local worker_events = require "resty.worker.events"

  local ok, err = worker_events.configure {
    shm = "kong_process_events", -- defined by "lua_shared_dict"
    timeout = 5,            -- life time of event data in shm
    interval = 1,           -- poll interval (seconds)

    wait_interval = 0.010,  -- wait before retry fetching event data
    wait_max = 0.5,         -- max wait time before discarding event
  }
  if not ok then
    return nil, err
  end

  return worker_events
end
```

é›†ç¾¤äº‹ä»¶ï¼ˆå¤šä¸ª Kong ä¹‹é—´çš„é€šä¿¡ï¼‰æ˜¯é€šè¿‡å°†äº‹ä»¶å‚¨å­˜åœ¨æ•°æ®åº“ä¸­ï¼Œå®šæ—¶è½®è¯¢æ•°æ®åº“æŸ¥è¯¢äº‹ä»¶ï¼Œè¿›è¡Œå¤„ç†ã€‚

```lua
function _GLOBAL.init_cluster_events(kong_config, db)
  return kong_cluster_events.new({
    db            = db,
    poll_interval = kong_config.db_update_frequency,
    poll_offset   = kong_config.db_update_propagation,
    poll_delay    = kong_config.db_update_propagation,
  })
end
```

ä»è¿™é‡Œå¯ä»¥çœ‹åˆ°é›†ç¾¤äº‹ä»¶æ˜¯é€šè¿‡æ•°æ®åº“è¡¨å®ç°çš„ï¼š

```lua
function _M:broadcast(channel, data, delay)
  if type(channel) ~= "string" then
    return nil, "channel must be a string"
  end

  if type(data) ~= "string" then
    return nil, "data must be a string"
  end

  if delay and type(delay) ~= "number" then
    return nil, "delay must be a number"

  elseif self.poll_delay > 0 then
    delay = self.poll_delay
  end

  -- insert event row

  --log(DEBUG, "broadcasting on channel: '", channel, "' data: ", data,
  --           " with delay: ", delay and delay or "none")

  local ok, err = self.strategy:insert(self.node_id, channel, nil, data, delay)
  if not ok then
    return nil, err
  end

  return true
end


function _M:subscribe(channel, cb, start_polling)
  if type(channel) ~= "string" then
    return error("channel must be a string")
  end

  if type(cb) ~= "function" then
    return error("callback must be a function")
  end

  if not self.callbacks[channel] then
    self.callbacks[channel] = { cb }

    insert(self.channels, channel)

  else
    insert(self.callbacks[channel], cb)
  end

  if start_polling == nil then
    start_polling = true
  end

  if not self.polling and start_polling and self.use_polling then
    -- start recurring polling timer

    local ok, err = timer_at(self.poll_interval, poll_handler, self)
    if not ok then
      return nil, "failed to start polling timer: " .. err
    end

    self.polling = true
  end

  return true
end
```

åœ¨ `cache.lua` ä¸­é›†ç¾¤äº‹ä»¶è®¢é˜… cache å¤±æ•ˆäº‹ä»¶ï¼Œå†…éƒ¨è°ƒç”¨ mlcache çš„ delete æ–¹æ³•ï¼ŒåŒæ­¥åˆ°æ‰€æœ‰çš„ Worker ä¸Šã€‚

```lua
  local ok, err = self.cluster_events:subscribe("invalidations", function(key)
    log(DEBUG, "received invalidate event from cluster for key: '", key, "'")
    self:invalidate_local(key)
  end)


function _M:invalidate_local(key, shadow)
  if type(key) ~= "string" then
    error("key must be a string", 2)
  end

  log(DEBUG, "invalidating (local): '", key, "'")

  local current_page = self.curr_mlcache or 1
  local delete_page
  if shadow and #self.mlcaches == 2 then
    delete_page = current_page == 1 and 2 or 1
  else
    delete_page = current_page
  end

  local ok, err = self.mlcaches[delete_page]:delete(key)
  if not ok then
    log(ERR, "failed to delete entity from node cache: ", err)
  end
end
```

è¿™éƒ¨åˆ†ä¸»è¦æè¿° Kong åˆå§‹åŒ–è¿‡ç¨‹ä¸­çš„äº‹ä»¶ç›¸å…³æ“ä½œï¼Œä¸»è¦æ˜¯åˆå§‹åŒ–äº‹ä»¶è®¢é˜…ï¼Œå…³è”åˆ° mlcache çš„ IPC è¿›ç¨‹é—´é€šä¿¡ï¼Œè®¢é˜… cache çš„å¤±æ•ˆäº‹ä»¶ï¼Œå¹¶å…³è” DAO çš„äº‹ä»¶å‘å¸ƒã€‚

```lua
function DB:set_events_handler(events)
  for _, dao in pairs(self.daos) do
    dao.events = events
  end
end
```

## 4. äº‹ä»¶åˆ†å‘

Kong ä¸­ä¼—å¤šéƒ¨åˆ†é€šè¿‡éé˜»å¡çš„ `ngx.timer.at()` å’Œ `ngx.timer.every()` å‡½æ•°æ‰§è¡Œå®šæ—¶ä»»åŠ¡ã€‚è¿™ä¸€éƒ¨åˆ†è¾ƒä¸ºåˆ†æ•£ï¼Œä¸»è¦å™è¿° Kong æ‰§è¡Œéé˜»å¡ä¸€æ¬¡æ€§äº‹ä»¶å¤„ç†ï¼Œå’Œå…¸å‹çš„å®šæ—¶ä»»åŠ¡ã€‚

### 4.1. å•æ¬¡ä»»åŠ¡

#### 4.1.1. DNS è§£æ

åœ¨ `cache_warmup.lua` ä¸­ç¼“å­˜ services å¯¹è±¡æ—¶ï¼ŒKong ä¼šéé˜»å¡åœ°è·å– services ä¸­ host å¯¹åº”çš„ ipã€‚

```lua
  if entity_name == "services" and host_count > 0 then
    ngx.timer.at(0, warmup_dns, hosts_array, host_count)
  end

local function warmup_dns(premature, hosts, count)
  if premature then
    return
  end

  ngx.log(ngx.NOTICE, "warming up DNS entries ...")

  local start = ngx.now()

  for i = 1, count do
    kong.dns.toip(hosts[i])
  end

  local elapsed = math.floor((ngx.now() - start) * 1000)

  ngx.log(ngx.NOTICE, "finished warming up DNS entries",
                      "' into the cache (in ", tostring(elapsed), "ms)")
end
```

Kong å†…éƒ¨ dns æ¨¡å—ä½¿ç”¨ **[lua-resty-dns-client](https://github.com/Kong/lua-resty-dns-client)**ï¼Œè¿™ä¸ªåº“ä¹Ÿæ˜¯ç”± Kong å¼€æºçš„ï¼Œç‰¹è‰²æœ‰ `toip` å‡½æ•°ä¼šæ ¹æ® dns è¿”å› ip çš„æƒé‡é…ç½®åŠ æƒè½®è¯¢çš„æƒé‡ï¼Œå‚¨å­˜ dns æŸ¥è¯¢çš„ç»“æœåœ¨å†…å­˜ä¸­ã€‚

`warmup_dns()` å†…è°ƒç”¨ `kong.dns.toip()` æ–¹æ³•ï¼š

```lua
local function warmup_dns(premature, hosts, count)
  if premature then
    return
  end

  ngx.log(ngx.NOTICE, "warming up DNS entries ...")

  local start = ngx.now()

  for i = 1, count do
    kong.dns.toip(hosts[i])
  end

  local elapsed = math.floor((ngx.now() - start) * 1000)

  ngx.log(ngx.NOTICE, "finished warming up DNS entries",
                      "' into the cache (in ", tostring(elapsed), "ms)")
end
```



### 4.2. å®šæ—¶ä»»åŠ¡

#### 4.2.1. é›†ç¾¤ä»»åŠ¡

`cluster_events/init.lua` ä¸­é›†ç¾¤äº‹æƒ…è®¢é˜…å‡½æ•°é‡Œå¯ç”¨å®šæ—¶å™¨è½®è¯¢æ•°æ®åº“é›†ç¾¤äº‹ä»¶è¡¨ã€‚

```lua
function _M:subscribe(channel, cb, start_polling)
  if type(channel) ~= "string" then
    return error("channel must be a string")
  end

  if type(cb) ~= "function" then
    return error("callback must be a function")
  end

  if not self.callbacks[channel] then
    self.callbacks[channel] = { cb }

    insert(self.channels, channel)

  else
    insert(self.callbacks[channel], cb)
  end

  if start_polling == nil then
    start_polling = true
  end

  if not self.polling and start_polling and self.use_polling then
    -- start recurring polling timer

    local ok, err = timer_at(self.poll_interval, poll_handler, self)
    if not ok then
      return nil, "failed to start polling timer: " .. err
    end

    self.polling = true
  end

  return true
end
```

è¿™é‡Œå› ä¸ºè¦åœ¨æ¯æ¬¡å¾ªç¯è°ƒç”¨æ—¶è¿›è¡Œé”çš„åˆ¤æ–­ï¼Œæ‰€ä»¥æ²¡æœ‰ä½¿ç”¨ `ngx.timer.every()` å‡½æ•°ï¼Œè€Œæ˜¯ç”¨æ— é™å¾ªç¯è°ƒç”¨ `ngx.timer.at()`ã€‚

```lua
poll_handler = function(premature, self)
  if premature or not self.polling then
    -- set self.polling to false to stop a polling loop
    return
  end

  if not get_lock(self) then
    local ok, err = timer_at(self.poll_interval, poll_handler, self)
    if not ok then
      log(CRIT, "failed to start recurring polling timer: ", err)
    end

    return
  end

  -- single worker

  local pok, perr, err = pcall(poll, self)
  if not pok then
    log(ERR, "poll() threw an error: ", perr)

  elseif not perr then
    log(ERR, "failed to poll: ", err)
  end

  -- unlock

  self.shm:delete(POLL_RUNNING_LOCK_KEY)

  local ok, err = timer_at(self.poll_interval, poll_handler, self)
  if not ok then
    log(CRIT, "failed to start recurring polling timer: ", err)
  end
end
```

é”é€šè¿‡å…±äº«å†…å­˜äº‹ä»¶ï¼Œä¿è¯åªæœ‰ä¸€ä¸ª Worker æ‰§è¡Œå•æ¬¡ä»»åŠ¡ã€‚

```lua
local function get_lock(self)
  -- check if a poll is not currently running, to ensure we don't start
  -- another poll while a worker is still stuck in its own polling (in
  -- case it is being slow)
  -- we still add an exptime to this lock in case something goes horribly
  -- wrong, to ensure other workers can poll new events
  -- a poll cannot take more than max(poll_interval * 5, 10) -- 10s min
  local ok, err = self.shm:safe_add(POLL_RUNNING_LOCK_KEY, true,
                                    max(self.poll_interval * 5, 10))
  if not ok then
    if err ~= "exists" then
      log(ERR, "failed to acquire poll_running lock: ", err)
    end
    -- else
    --   log(DEBUG, "failed to acquire poll_running lock: ",
    --              "a worker still holds the lock")

    return false
  end

  if self.poll_interval > 0.001 then
    -- check if interval of `poll_interval` has elapsed already, to ensure
    -- we do not run the poll when a previous poll was quickly executed, but
    -- another worker got the timer trigger a bit too late.
    ok, err = self.shm:safe_add(POLL_INTERVAL_LOCK_KEY, true,
                                self.poll_interval - 0.001)
    if not ok then
      if err ~= "exists" then
        log(ERR, "failed to acquire poll_interval lock: ", err)
      end
      -- else
      --   log(DEBUG, "failed to acquire poll_interval lock: ",
      --              "not enough time elapsed since last poll")

      self.shm:delete(POLL_RUNNING_LOCK_KEY)

      return false
    end
  end

  return true
end
```

#### 4.2.2. æ•°æ®åº“ TTL

ä¸ºç»™ PostgreSQL åŠ ä¸Š TTLï¼ŒKong åœ¨ `init_worker` é˜¶æ®µè°ƒç”¨æ•°æ®åº“å±‚ `db/strategies/postgres/connector.lua` ä¸­ `init_worker()` å‡½æ•°ã€‚

```lua
-- ä»¥ä¸‹çœç•¥éƒ¨åˆ†å†…å®¹ï¼Œåªå±•ç¤ºå…³é”®éƒ¨åˆ†
function _mt:init_worker(strategies)
  if ngx.worker.id() == 0 then

      cleanup_statements[i] = concat {
        "  DELETE FROM ",
        self:escape_identifier(table_name),
        " WHERE ",
        column_name,
        " < CURRENT_TIMESTAMP AT TIME ZONE 'UTC';"
      }

    local cleanup_statement = concat(cleanup_statements, "\n")

    return timer_every(60, function(premature)

      local ok, err, _, num_queries = self:query(cleanup_statement)
      if not ok then
        if num_queries then
          for i = num_queries + 1, cleanup_statements_count do
            local statement = cleanup_statements[i]
            local ok, err = self:query(statement)
            if not ok then
              if err then
                log(WARN, "unable to clean expired rows from table '",
                          sorted_strategies[i], "' on PostgreSQL database (",
                          err, ")")
              else
                log(WARN, "unable to clean expired rows from table '",
                          sorted_strategies[i], "' on PostgreSQL database")
              end
            end
          end

        else
          log(ERR, "unable to clean expired rows from PostgreSQL database (", err, ")")
        end
      end
    end)
  end

  return true
end
```

æ•°æ®åº“åˆå§‹åŒ–æ—¶æ–°å¢ä¸€ä¸ª `timer`ï¼Œåœ¨åç¨‹ä¸­è°ƒç”¨å›è°ƒå‡½æ•°ï¼Œåˆ é™¤ TTL è¿‡æœŸçš„ rowsã€‚

#### 4.2.3. æ›´æ–°è·¯ç”±ç´¢å¼•

`kong.init_worker()` ä¼šæ·»åŠ å®šæ—¶ä»»åŠ¡ï¼Œå®šæ—¶æ›´æ–°ç¼“å­˜ã€‚

```lua
      -- å®šæ—¶é‡å»ºè·¯ç”±ç¼“å­˜
      if kong.db.strategy ~= "off" then
        timer_every(worker_state_update_frequency, function(premature)
          if premature then
            return
          end

          -- Don't wait for the semaphore (timeout = 0) when updating via the
          -- timer.
          -- If the semaphore is locked, that means that the rebuild is
          -- already ongoing.
          local ok, err = rebuild_router(ROUTER_ASYNC_OPTS)
          if not ok then
            log(ERR, "could not rebuild router via timer: ", err)
          end
        end)

        timer_every(worker_state_update_frequency, function(premature)
          if premature then
            return
          end

          local ok, err = rebuild_plugins_iterator(PLUGINS_ITERATOR_ASYNC_OPTS)
          if not ok then
            log(ERR, "could not rebuild plugins iterator via timer: ", err)
          end
        end)
      end
```

å®é™…è°ƒç”¨é¡ºåºæ˜¯å¼€ä¸€ä¸ª cosocket åç¨‹ï¼Œåˆ¤æ–­ routes æ˜¯å¦æœ‰å˜åŒ–ï¼Œå˜åŒ–åˆ™é‡æ„è·¯ç”±ç¼“å­˜ã€‚

```lua
  rebuild_router = function(opts)
    return rebuild("router", update_router, router_version, opts)
  end

local function rebuild(name, callback, version, opts)
  local current_version, err = kong.core_cache:get(name .. ":version", TTL_ZERO,
                                                   utils.uuid)
  if err then
    return nil, "failed to retrieve " .. name .. " version: " .. err
  end

  if current_version == version then
    return true
  end

  -- å¼€ä¸€ä¸ª cosocket åç¨‹è°ƒç”¨ callback
  return concurrency.with_coroutine_mutex(opts, callback)
end

  update_router = function()
    -- we might not need to rebuild the router (if we were not
    -- the first request in this process to enter this code path)
    -- check again and rebuild only if necessary
    local version, err = get_router_version()
    if err then
      return nil, "failed to retrieve router version: " .. err
    end

    if version == router_version then
      return true
    end

    local ok, err = build_router(version)
    if not ok then
      return nil, --[[ 'err' fully formatted ]] err
    end

    return true
  end
```

æœ€ç»ˆè¿˜ä¼šè°ƒç”¨åˆ° `build_router()` æ–¹æ³•ï¼Œæˆ‘ä»¬å·²ç»åœ¨ 1.2.1 ä¸­æè¿°è¿‡ã€‚

## 5. äº‹ä»¶å¤„ç†

Worker é—´çš„äº‹ä»¶å¤„ç†ä½¿ç”¨ `lua-resty-worker-events` åº“ã€‚

äº‹ä»¶è®¢é˜…å‡½æ•°ï¼š`events.register(callback, source, event1, event2, ...)`ï¼Œcallback æ–¹æ³• `callback = function(data, event, source, pid)`ã€‚

äº‹ä»¶å‘å¸ƒå‡½æ•°ï¼š`success, err = events.post(source, event, data, unique)`

### 5.1. æ•°æ®åº“äº‹ä»¶

`db/dao/init.lua` ä¸­å®šä¹‰äº† DAO ç›¸å…³çš„æ“ä½œæ–¹æ³•ï¼Œæˆ‘å·²ç»åœ¨ 1.1.3 ä¸­ç®€å•é˜è¿°è¿‡äº†ã€‚

æ•°æ®åº“ç›¸å…³å®ä½“çš„ CRUDï¼ˆå…¶å®æ²¡æœ‰Rï¼‰äº‹ä»¶æœ€åä¼šè°ƒç”¨ `DAO:post_crud_event()` æ–¹æ³•å¹¿æ’­äº‹ä»¶ã€‚

```lua
function DAO:post_crud_event(operation, entity, old_entity, options)
  if options and options.no_broadcast_crud_event then
    return
  end

  if self.events then
    local entity_without_nulls
    if entity then
      entity_without_nulls = remove_nulls(utils.deep_copy(entity, false))
    end

    local old_entity_without_nulls
    if old_entity then
      old_entity_without_nulls = remove_nulls(utils.deep_copy(old_entity, false))
    end

    local ok, err = self.events.post_local("dao:crud", operation, {
      operation  = operation,
      schema     = self.schema,
      entity     = entity_without_nulls,
      old_entity = old_entity_without_nulls,
    })
    if not ok then
      log(ERR, "[db] failed to propagate CRUD operation: ", err)
    end
  end
end
```

åœ¨ `dao:crud` é€šé“å‘å¸ƒäº†ä¸€ä¸ªäº‹ä»¶ï¼Œoperation ç±»å‹æœ‰ createã€updateã€deleteã€‚

`runloop/handler.lua` ä¸­ `register_events()` ä¼šåœ¨ `kong.init_worker()` ä¸­è¢«è°ƒç”¨ï¼Œæ­¤æ—¶ä¼šè®¢é˜…æ•°æ®åº“ç›¸å…³äº‹ä»¶ï¼Œæ·»åŠ å¤„ç†å‡½æ•°ã€‚

```lua
  worker_events.register(function(data)
    if not data.schema then
      log(ERR, "[events] missing schema in crud subscriber")
      return
    end

    if not data.entity then
      log(ERR, "[events] missing entity in crud subscriber")
      return
    end

    -- invalidate this entity anywhere it is cached if it has a
    -- caching key
    -- å¦‚æœ entity æœ‰ cache_key åˆ™è®©å®ƒå¤±æ•ˆ
    -- åŸºæœ¬ä¸Šä¹Ÿåªæœ‰ entity schema å®šä¹‰å‡ºé”™çš„æƒ…å†µä¸‹æ‰ä¸ä¼šæœ‰ cache_key

    local cache_key = db[data.schema.name]:cache_key(data.entity)
    local cache_obj = kong[constants.ENTITY_CACHE_STORE[data.schema.name]]

    if cache_key then
      cache_obj:invalidate(cache_key)
    end

    -- if we had an update, but the cache key was part of what was updated,
    -- we need to invalidate the previous entity as well

    if data.old_entity then
      local old_cache_key = db[data.schema.name]:cache_key(data.old_entity)
      if old_cache_key and cache_key ~= old_cache_key then
        cache_obj:invalidate(old_cache_key)
      end
    end

    if not data.operation then
      log(ERR, "[events] missing operation in crud subscriber")
      return
    end

    -- public worker events propagation

    -- è·å– schema åå­—
    local entity_channel           = data.schema.table or data.schema.name
    local entity_operation_channel = fmt("%s:%s", entity_channel,
      data.operation)

    -- crud:routes
    local ok, err = worker_events.post_local("crud", entity_channel, data)
    if not ok then
      log(ERR, "[events] could not broadcast crud event: ", err)
      return
    end

    -- crud:routes:create
    ok, err = worker_events.post_local("crud", entity_operation_channel, data)
    if not ok then
      log(ERR, "[events] could not broadcast crud event: ", err)
      return
    end
  end, "dao:crud")
```

CRUDï¼ˆæ²¡æœ‰ Rï¼‰äº‹ä»¶å¤„ç†æµç¨‹ï¼šè°ƒç”¨ `cache:invalidate()` æ–¹æ³•ï¼Œæ–¹æ³•å†…éƒ¨å‘å¸ƒäº†ä¸€ä¸ª worker çº§äº‹ä»¶ï¼Œé€šçŸ¥ worker è¿›ç¨‹åˆ é™¤è¯¥æ•°æ®ï¼Œè¿˜ä¼šå‘å¸ƒä¸€ä¸ªé›†ç¾¤äº‹ä»¶ï¼Œåœ¨é›†ç¾¤é—´åŒæ­¥åˆ é™¤æ•°æ®ã€‚

```lua
  -- ä¿®æ”¹äº† Routes åä¼šæ¸…ç©º router:version ç¼“å­˜ï¼Œ
  -- ä¼šå¯¼è‡´é‡æ–°æ„å»ºè·¯ç”±è¡¨ï¼Œè¯¦æƒ…æŸ¥çœ‹ 2.2.3
  worker_events.register(function()
    log(DEBUG, "[events] Route updated, invalidating router")
    core_cache:invalidate("router:version")
  end, "crud", "routes")

...å…¶ä»–å¯¹è±¡åŒç†
```

## 6. æ’ä»¶åŠ è½½

### 6.1. æ’ä»¶è¯»å–

`init` é˜¶æ®µä¼šåŠ è½½é…ç½®æ–‡ä»¶ä¸­ `plugins=bundled,skywalking-intergrator` çš„æ’ä»¶åˆ—è¡¨ï¼Œè°ƒç”¨ Lua `require` åŠ è½½å¯¹åº”çš„åŒ…ã€‚ï¼ˆæ‰€æœ‰çš„æ’ä»¶åŒ…éƒ½è¦æ±‚åœ¨ `kong.plugins` ä¸‹ï¼‰

```lua
function Plugins:load_plugin_schemas(plugin_set)
  self.handlers = nil

  local go_plugins_cnt = 0
  local handlers = {}
  local errs

  -- load installed plugins
  for plugin in pairs(plugin_set) do
    local handler, err = load_plugin(self, plugin)

    if handler then
      if type(handler.is) == "function" and handler:is(BasePlugin) then
        -- Backwards-compatibility for 0.x and 1.x plugins inheriting from the
        -- BasePlugin class.
        -- TODO: deprecate & remove
        handler = handler()
      end

      if handler._go then
        go_plugins_cnt = go_plugins_cnt + 1
      end

      handlers[plugin] = handler

    else
      errs = errs or {}
      table.insert(errs, "on plugin '" .. plugin .. "': " .. tostring(err))
    end
  end

  if errs then
    return nil, "error loading plugin schemas: " .. table.concat(errs, "; ")
  end

  reports.add_immutable_value("go_plugins_cnt", go_plugins_cnt)

  self.handlers = handlers

  return true
end
```

æ‰€æœ‰æ’ä»¶çš„ Handler å‡½æ•°ä¼šè¢«å‚¨å­˜åœ¨ `kong.db.plugins.handlers`ï¼Œæ•°æ®æ ¼å¼ä¸º `{plugin_name: handler}`ã€‚

æ‰€æœ‰çš„æ’ä»¶ä¼šå‚¨å­˜åˆ° Worker è¿›ç¨‹ä¸Šï¼Œå‘¨æœŸæ€§è¿›è¡ŒåŒæ­¥æ›´æ–°ã€‚

æˆ‘æ•´ç†äº†æ’ä»¶è¡¨åŠ è½½åˆ° Lua table çš„ç»“æ„ï¼Œè¾“å‡ºæˆ YAMLï¼Œæ–¹ä¾¿ç†è§£ï¼š

```yaml
map:
  plugin_name: true

combos:
  plugin_name:
    # both: {}
    both:
      route_id: service_id
    # routes: {}
    routes:
      route_id: true
    # services: {}
    services:
      service_id: true
    0: true # å…¨å±€æ’ä»¶
    1: true # è·¯ç”±æ’ä»¶
    2: true # Service æ’ä»¶
    3: true # è·¯ç”±+Service
    4: true # Consumer æ’ä»¶
    5: true # è·¯ç”±+Consumer æ’ä»¶
    6: true # è·¯ç”±+Service+Consumer æ’ä»¶

loaded:
  plugin_name:
    handler:
      phase_name: func()
```

### 6.2. æ’ä»¶è°ƒç”¨

æ’ä»¶ä¸ç›´æ¥å’Œè·¯ç”±è¿›è¡Œç»‘å®šï¼Œæ’ä»¶æœ‰è‡ªå·±çš„ç”Ÿå‘½å‘¨æœŸï¼Œå’Œ Kong çš„ç”Ÿå‘½å‘¨æœŸåŸºæœ¬ç›¸åŒã€‚åœ¨ Kong ç”Ÿå‘½å‘¨æœŸçš„å„ä¸ªé˜¶æ®µä¼šè°ƒç”¨æ’ä»¶çš„å¯¹åº”æ–¹æ³•ã€‚

æ’ä»¶åªåœ¨è°ƒç”¨é˜¶æ®µè¿›è¡Œåˆ¤æ–­ï¼Œæ˜¯å¦å…³è”å½“å‰ Routeã€Serviceã€å’Œ Consumerï¼Œæœ‰åˆ™ä»æ•°æ®åº“è¯»å–æ’ä»¶å…³è”çš„é…ç½®é¡¹ï¼ˆæ’ä»¶ Entityï¼‰ï¼Œå¹¶ä½¿ç”¨ `kong.core_cache` è¿›è¡Œç¼“å­˜ã€‚

```lua
local function load_configuration_through_combos(ctx, combos, plugin)
  local plugin_configuration
  local name = plugin.name

  local route    = ctx.route
  local service  = ctx.service
  local consumer = ctx.authenticated_consumer

  if route and plugin.no_route then
    route = nil
  end
  if service and plugin.no_service then
    service = nil
  end
  if consumer and plugin.no_consumer then
    consumer = nil
  end

  local    route_id = route    and    route.id or nil
  local  service_id = service  and  service.id or nil
  local consumer_id = consumer and consumer.id or nil

  if kong.db.strategy == "off" then
	...
  else
    if route_id and service_id and consumer_id and combos[COMBO_RSC]
      and combos.both[route_id] == service_id
    then
      plugin_configuration = load_configuration(ctx, name, route_id, service_id,
                                                consumer_id)
      if plugin_configuration then
        return plugin_configuration
      end
    end

    if consumer_id and combos[COMBO_C] then
      plugin_configuration = load_configuration(ctx, name, nil, nil, consumer_id)
      if plugin_configuration then
        return plugin_configuration
      end
    end

    if route_id and combos[COMBO_R] and combos.routes[route_id] then
      plugin_configuration = load_configuration(ctx, name, route_id)
      if plugin_configuration then
        return plugin_configuration
      end
    end

    ...

    if combos[COMBO_GLOBAL] then
      return load_configuration(ctx, name)
    end
  end
end
```

è¿™é‡Œä¼šæŸ¥è¯¢å½“å‰ Serviceã€Route å’Œ Consumer æ˜¯å¦ä¸æŸä¸ªæ’ä»¶é…å¯¹ï¼ŒæˆåŠŸåˆ™åŠ è½½å¯¹åº”çš„é…ç½®é¡¹ï¼š

```lua
--- Load the configuration for a plugin entry.
-- Given a Route, Service, Consumer and a plugin name, retrieve the plugin's
-- configuration if it exists. Results are cached in ngx.dict
-- @param[type=string] name Name of the plugin being tested for configuration.
-- @param[type=string] route_id Id of the route being proxied.
-- @param[type=string] service_id Id of the service being proxied.
-- @param[type=string] consumer_id Id of the donsumer making the request (if any).
-- @treturn table Plugin configuration, if retrieved.
local function load_configuration(ctx,
                                  name,
                                  route_id,
                                  service_id,
                                  consumer_id)
  local ws_id = workspaces.get_workspace_id() or kong.default_workspace
  local key = kong.db.plugins:cache_key(name,
                                        route_id,
                                        service_id,
                                        consumer_id,
                                        nil,
                                        ws_id)
  local plugin, err = kong.core_cache:get(key,
                                          nil,
                                          load_plugin_from_db,
                                          key)
  if err then
    ctx.delay_response = false
    ngx.log(ngx.ERR, tostring(err))
    return ngx.exit(ngx.ERROR)
  end

  if not plugin or not plugin.enabled then
    return
  end

  local cfg = plugin.config or {}

  if not cfg.__key__ then
    cfg.__key__ = key
    cfg.__seq__ = next_seq
    next_seq = next_seq + 1
  end

  cfg.route_id    = plugin.route and plugin.route.id
  cfg.service_id  = plugin.service and plugin.service.id
  cfg.consumer_id = plugin.consumer and plugin.consumer.id

  return cfg
end
```

æ’ä»¶çš„è°ƒç”¨æœ‰ä¸¤ç§æ–¹å¼ï¼š

1. åŒæ­¥è°ƒç”¨
2. å¼‚æ­¥è°ƒç”¨

é™¤äº† `access_by_lua` é˜¶æ®µï¼Œéƒ½æ˜¯ä½¿ç”¨åŒæ­¥è°ƒç”¨ï¼š

```lua
local function execute_plugins_iterator(plugins_iterator, phase, ctx)
  local old_ws = ctx and ctx.workspace
  for plugin, configuration in plugins_iterator:iterate(phase, ctx) do
    if ctx then
      if plugin.handler._go then
        ctx.ran_go_plugin = true
      end

      kong_global.set_named_ctx(kong, "plugin", plugin.handler)
    end

    kong_global.set_namespaced_log(kong, plugin.name)
    -- è¿™é‡Œæ˜¯åŒæ­¥è°ƒç”¨
    plugin.handler[phase](plugin.handler, configuration)
    kong_global.reset_log(kong)

    if ctx then
      ctx.workspace = old_ws
    end
  end
end
```

è€Œåœ¨ `access_by_lua` é˜¶æ®µï¼Œä½¿ç”¨åç¨‹å¼‚æ­¥è°ƒç”¨ï¼š

```lua
  for plugin, plugin_conf in plugins_iterator:iterate("access", ctx) do
    if plugin.handler._go then
      ctx.ran_go_plugin = true
    end

    if not ctx.delayed_response then
      kong_global.set_named_ctx(kong, "plugin", plugin.handler)
      kong_global.set_namespaced_log(kong, plugin.name)

      -- ä½¿ç”¨ Lua coroutine å¼€å¯åç¨‹å¼‚æ­¥è°ƒç”¨æ’ä»¶å‡½æ•°
      local err = coroutine.wrap(plugin.handler.access)(plugin.handler, plugin_conf)
      if err then
        kong.log.err(err)
        ctx.delayed_response = {
          status_code = 500,
          content     = { message  = "An unexpected error occurred" },
        }
      end

      kong_global.reset_log(kong)
    end
    ctx.workspace = old_ws
  end
```

## 7. ç¼“å­˜æœºåˆ¶

æœ¬èŠ‚æ ¹æ®æˆ‘å¯¹ Kong æºç çš„åˆ†æï¼Œåšä¸€ä¸ªç¼“å­˜æœºåˆ¶çš„å°å›é¡¾ã€‚

Kong é’ˆå¯¹ç¼“å­˜æœ‰è¿™äº›æ“ä½œï¼š

- åˆå§‹åŒ–ç¼“å­˜å—
- é¢„è½½åŠ è½½æ•°æ®åº“å†…å®¹åˆ°ç¼“å­˜
- è®¿é—®æ—¶æ‰åŠ è½½çš„æ•°æ®å†…å®¹æ·»åŠ åˆ°ç¼“å­˜
- timer å®šæ—¶æ›´æ–°ç¼“å­˜
- æ•°æ®åº“ CRUD æ“ä½œåˆ é™¤ç¼“å­˜
- é›†ç¾¤/Worker é—´åŒæ­¥ç¼“å­˜

ç¼“å­˜åŠ è½½å†…å®¹ï¼š

é»˜è®¤é…ç½®ä¸‹ï¼ŒKong å°†è·¯ç”±è¡¨å’Œ Routes å…¨é‡åŠ è½½åˆ°æ¯ä¸ª Worker çš„å†…å­˜ï¼ŒServices å’Œ Plugins å…¨é‡åŠ è½½åˆ°æ¯ä¸ª Worker çš„å†…å­˜å’Œå…±äº«å†…å­˜ä¸­ã€‚Upstreams å’Œ Targets æ ¹æ®è´Ÿè½½å‡è¡¡å™¨çš„è§£æåŠæ—¶ä»æ•°æ®åº“è·å–ï¼ŒåŠ è½½åˆ°å†…å­˜å’Œå…±äº«å†…å­˜ä¸­ã€‚

ä¸Šè¿° Entity åŠ è½½åœ¨ç”± mlcache åº“åˆ›å»ºçš„ L1+L2 ä¸¤çº§ç¼“å­˜ `core_cache` ä¸­ã€‚

è€Œ consumers åŠ è½½åˆ°åŒä¸º mlcache åˆ›å»ºçš„ä¸åŒåçš„ `cache` ä¸­ã€‚

##  8. è¯·æ±‚ç”Ÿå‘½å‘¨æœŸ

æœ¬èŠ‚è®²è¿°ä¸€ä¸ªè¯·æ±‚ç»è¿‡ Kong å¤„ç†çš„æµç¨‹ã€‚

### 8.1. ssl_certificate_by_lua é˜¶æ®µ

```lua
local function execute()
  local sn, err = server_name()
  if err then
    log(ERR, "could not retrieve SNI: ", err)
    return ngx.exit(ngx.ERROR)
  end

  local cert_and_key, err = find_certificate(sn)
  if err then
    log(ERR, err)
    return ngx.exit(ngx.ERROR)
  end

  if cert_and_key == default_cert_and_key then
    -- use (already set) fallback certificate
    return
  end

  -- set the certificate for this connection

  local ok, err = clear_certs()
  if not ok then
    log(ERR, "could not clear existing (default) certificates: ", err)
    return ngx.exit(ngx.ERROR)
  end

  ok, err = set_cert(cert_and_key.cert)
  if not ok then
    log(ERR, "could not set configured certificate: ", err)
    return ngx.exit(ngx.ERROR)
  end

  ok, err = set_priv_key(cert_and_key.key)
  if not ok then
    log(ERR, "could not set configured private key: ", err)
    return ngx.exit(ngx.ERROR)
  end
end
```

æ ¹æ® Server Name æŸ¥æ‰¾å¯¹åº” SSL è¯ä¹¦ Cert å’Œç§é’¥å¹¶è®¾ç½®åœ¨ Nginx ä¸Šã€‚

### 8.2. rewrite_by_lua é˜¶æ®µ

```lua
  local ctx = ngx.ctx
  if not ctx.KONG_PROCESSING_START then
    ctx.KONG_PROCESSING_START = ngx.req.start_time() * 1000
  end

  if not ctx.KONG_REWRITE_START then
    ctx.KONG_REWRITE_START = get_now_ms()
  end

  kong_global.set_phase(kong, PHASES.rewrite)
  kong_resty_ctx.stash_ref()

  local is_https = var.https == "on"
  if not is_https then
    log_init_worker_errors(ctx)
  end

  runloop.rewrite.before(ctx)

...

  rewrite = {
    before = function(ctx)
      ctx.host_port = HOST_PORTS[var.server_port] or var.server_port

      -- special handling for proxy-authorization and te headers in case
      -- the plugin(s) want to specify them (store the original)
      ctx.http_proxy_authorization = var.http_proxy_authorization
      ctx.http_te                  = var.http_te
    end,
  },
```

åˆå§‹åŒ– `kong.ctx` ç”Ÿå‘½å‘¨æœŸ Contextï¼Œä¸º Context æ·»åŠ è¯·æ±‚ä¿¡æ¯ã€‚

### 8.3. access_by_lua é˜¶æ®µ

#### 8.3.1. è·¯ç”±åŒ¹é…

`runloop.access.before` ä¼šè¿›è¡Œè°ƒç”¨ `Router` å®ä¾‹è¿›è¡Œè·¯ç”±åŒ¹é…ã€‚é¦–å…ˆä¼šè°ƒç”¨ `get_updated_router()` åˆ¤æ–­æ˜¯å¦æœ‰è·¯ç”±æ›´æ–°ï¼Œæ²¡æœ‰åˆ™è¿”å›å½“å‰ `Router` å®ä¾‹ã€‚

```lua
      -- routing request
      local router = get_updated_router()
	  -- è°ƒç”¨ Router.exec() æŸ¥æ‰¾åŒ¹é…çš„è·¯ç”±
      local match_t = router.exec()
      if not match_t then
        return kong.response.exit(404, { message = "no Route matched with those values" })
      end
```

`Router.exec()` æ–¹æ³•æœ€ç»ˆä¼šè°ƒç”¨ `Router.find_route()` æ–¹æ³•ï¼Œè¯¥æ–¹æ³•æ¥æ”¶è¯·æ±‚å¤´å­—æ®µï¼Œå¹¶ç”Ÿæˆè·¯ç”± Cache Keyï¼ŒæŸ¥æ‰¾å¯¹åº”çš„é¡¹ç›®ã€‚

```lua
  local function find_route(req_method, req_uri, req_host, req_scheme,
                            src_ip, src_port,
                            dst_ip, dst_port,
                            sni, req_headers)

    req_method = req_method or ""
    req_uri = req_uri or ""
    req_host = req_host or ""
    req_headers = req_headers or EMPTY_T

    ctx.req_method     = req_method
    ctx.req_uri        = req_uri
    ctx.req_host       = req_host
    ctx.req_headers    = req_headers
    ctx.src_ip         = src_ip or ""
    ctx.src_port       = src_port or ""
    ctx.dst_ip         = dst_ip or ""
    ctx.dst_port       = dst_port or ""
    ctx.sni            = sni or ""

    local cache_key = req_method .. "|" .. req_uri .. "|" .. req_host ..
                      "|" .. ctx.src_ip .. "|" .. ctx.src_port ..
                      "|" .. ctx.dst_ip .. "|" .. ctx.dst_port ..
                      "|" .. ctx.sni

    do
      local match_t = cache:get(cache_key)
      if match_t and hits.header_name == nil then
        return match_t
      end
    end
```

å¦‚æœ LRU ç¼“å­˜ä¸­æœ‰åŒ¹é…è·¯ç”±ï¼Œåˆ™ç›´æ¥è¿”å›ã€‚

å¦åˆ™ç»§ç»­åŒ¹é…è·¯ç”±ï¼Œç”ŸæˆåŒ¹é…é¡¹ç›®ï¼Œå¹¶å­˜å…¥ç¼“å­˜ä¸­ã€‚

```lua
              ...
              local match_t     = {
                  route           = matched_route.route,
                  service         = matched_route.service,
                  headers         = matched_route.headers,
                  upstream_url_t  = upstream_url_t,
                  upstream_scheme = upstream_url_t.scheme,
                  upstream_uri    = upstream_uri,
                  upstream_host   = upstream_host,
                  prefix          = request_prefix,
                  matches         = {
                    uri_captures  = matches.uri_captures,
                    uri           = matches.uri,
                    host          = matches.host,
                    headers       = matches.headers,
                    method        = matches.method,
                    src_ip        = matches.src_ip,
                    src_port      = matches.src_port,
                    dst_ip        = matches.dst_ip,
                    dst_port      = matches.dst_port,
                    sni           = matches.sni,
                  }
                }

                if band(matched_route.match_rules, MATCH_RULES.HEADER) == 0 then
                  cache:set(cache_key, match_t)
                end
                ...
```

åŒ¹é…æˆåŠŸåä¼šå°†å…³è”çš„ Route å’Œ Service å†™å…¥ `ngx.ctx` ï¼Œåœ¨æ¥ä¸‹æ¥çš„ç”Ÿå‘½å‘¨æœŸä¸­å…±äº«ã€‚

#### 8.3.2. è¯·æ±‚è°ƒåº¦

`runloop.access.after` ä¸­æ ¹æ® Routeã€Service ç­‰æ¡ä»¶è§£æå‡ºåç«¯è¦è¯·æ±‚çš„ IPã€Portã€Schema ç­‰å‚æ•°ã€‚

```lua
-- looks up a balancer for the target.
-- @param target the table with the target details
-- @param no_create (optional) if true, do not attempt to create
-- (for thorough testing purposes)
-- @return balancer if found, `false` if not found, or nil+error on error
local function get_balancer(target, no_create)
  -- NOTE: only called upon first lookup, so `cache_only` limitations
  -- do not apply here
  local hostname = target.host


  -- first go and find the upstream object, from cache or the db
  local upstream, err = get_upstream_by_name(hostname)
  if upstream == false then
    return false -- no upstream by this name
  end
  if err then
    return nil, err -- there was an error
  end

  local balancer = balancers[upstream.id]
  if not balancer then
    if no_create then
      return nil, "balancer not found"
    else
      log(ERR, "balancer not found for ", upstream.name, ", will create it")
      return create_balancer(upstream), upstream
    end
  end

  return balancer, upstream
end
```

`get_balancer()` æ ¹æ® Service çš„ Host è¿”å›æœ€ç»ˆè¯·æ±‚çš„ Targetï¼Œå’Œè´Ÿè½½å‡è¡¡å™¨ã€‚

```lua
  local ip, port, hostname, handle
  if balancer then
    -- have to invoke the ring-balancer
    local hstate = run_hook("balancer:get_peer:pre", target.host)
    ip, port, hostname, handle = balancer:getPeer(dns_cache_only,
                                          target.balancer_handle,
                                          hash_value)
    run_hook("balancer:get_peer:post", hstate)
    if not ip and
      (port == "No peers are available" or port == "Balancer is unhealthy") then
      return nil, "failure to get a peer from the ring-balancer", 503
    end
    hostname = hostname or ip
    target.hash_value = hash_value
    target.balancer_handle = handle

  else
    -- have to do a regular DNS lookup
    local try_list
    local hstate = run_hook("balancer:to_ip:pre", target.host)
    ip, port, try_list = toip(target.host, target.port, dns_cache_only)
    run_hook("balancer:to_ip:post", hstate)
    hostname = target.host
    if not ip then
      log(ERR, "DNS resolution failed: ", port, ". Tried: ", tostring(try_list))
      if port == "dns server error: 3 name error" or
         port == "dns client error: 101 empty record received" then
        return nil, "name resolution failed", 503
      end
    end
  end
```

è°ƒç”¨è´Ÿè½½å‡è¡¡å™¨çš„ç­–ç•¥è·å– Target çš„ IPï¼Œæˆ–è€…ç›´æ¥ä½¿ç”¨ DNS æŸ¥è¯¢è·å– IP åœ°å€ï¼Œè¿™ä¸€æ­¥åœ¨ 2.1.1 ä¸­å·²ç»æå‰è¿›è¡Œäº† DNS é¢„ç¼“å­˜ï¼Œè¿™é‡Œå¯ä»¥ä»ç¼“å­˜ä¸­è¯»å–ã€‚

å¦‚æœ Service Host ç›´æ¥æ˜¯ IP åœ°å€ï¼Œåˆ™ä¸æ‰§è¡Œè´Ÿè½½å‡è¡¡ç­–ç•¥ã€‚

```lua
  -- ip åˆ™ç›´æ¥è¿”å›
  if target.type ~= "name" then
    -- it's an ip address (v4 or v6), so nothing we can do...
    target.ip = target.host
    target.port = target.port or 80 -- TODO: remove this fallback value
    target.hostname = target.host
    return true
  end
```

### 8.4. balancer_by_lua é˜¶æ®µ

ä½¿ç”¨ `ngx.balancer.set_more_tries()` è®¾ç½®é”™è¯¯é‡è¯•æ¬¡æ•°ï¼Œä½¿ç”¨ `ngx.balancer.get_last_failure()` è·å–ä¸Šä¸€æ¬¡è¯·æ±‚é”™è¯¯è¯¦æƒ…ï¼Œåœ¨é”™è¯¯å¤„ç†ä¸­è¿›è¡Œå¯¹ä¸Šæ¸¸èŠ‚ç‚¹è¿›è¡Œè¢«åŠ¨å¥åº·æ£€æŸ¥ã€‚

```lua
  if balancer_data.try_count > 1 then
    -- only call balancer on retry, first one is done in `runloop.access.after`
    -- which runs in the ACCESS context and hence has less limitations than
    -- this BALANCER context where the retries are executed

    -- record failure data
    local previous_try = tries[balancer_data.try_count - 1]
    previous_try.state, previous_try.code = get_last_failure()

    -- Report HTTP status for health checks
    local balancer = balancer_data.balancer
    if balancer then
      if previous_try.state == "failed" then
        if previous_try.code == 504 then
          balancer.report_timeout(balancer_data.balancer_handle)
        else
          balancer.report_tcp_failure(balancer_data.balancer_handle)
        end

      else
        balancer.report_http_status(balancer_data.balancer_handle,
                                    previous_try.code)
      end
    end

    local ok, err, errcode = balancer_execute(balancer_data)
    if not ok then
      ngx_log(ngx_ERR, "failed to retry the dns/balancer resolver for ",
              tostring(balancer_data.host), "' with: ", tostring(err))

      ctx.KONG_BALANCER_ENDED_AT = get_now_ms()
      ctx.KONG_BALANCER_TIME = ctx.KONG_BALANCER_ENDED_AT - ctx.KONG_BALANCER_START
      ctx.KONG_PROXY_LATENCY = ctx.KONG_BALANCER_ENDED_AT - ctx.KONG_PROCESSING_START

      return ngx.exit(errcode)
    end

  else
    -- first try, so set the max number of retries
    local retries = balancer_data.retries
    if retries > 0 then
      set_more_tries(retries)
    end
  end
```

è¯·æ±‚åˆ°æœ€ç»ˆè§£æçš„åç«¯æœåŠ¡ï¼Œä½¿ç”¨ `ngx.balancer.set_current_peer()` æ–¹æ³•è®¾ç½®è®¿é—®çš„åœ°å€ã€‚

```lua
  -- set the targets as resolved
  ngx_log(ngx_DEBUG, "setting address (try ", balancer_data.try_count, "): ",
                     balancer_data.ip, ":", balancer_data.port)
  -- æœ€ç»ˆè°ƒåº¦çš„åœ°å€
  local ok, err = set_current_peer(balancer_data.ip, balancer_data.port, pool_opts)
  if not ok then
    ngx_log(ngx_ERR, "failed to set the current peer (address: ",
            tostring(balancer_data.ip), " port: ", tostring(balancer_data.port),
            "): ", tostring(err))

    ctx.KONG_BALANCER_ENDED_AT = get_now_ms()
    ctx.KONG_BALANCER_TIME = ctx.KONG_BALANCER_ENDED_AT - ctx.KONG_BALANCER_START
    ctx.KONG_PROXY_LATENCY = ctx.KONG_BALANCER_ENDED_AT - ctx.KONG_PROCESSING_START

    return ngx.exit(500)
  end
```

### 8.5. header_filter_by_lua é˜¶æ®µ

æ­¤é˜¶æ®µåœ¨ Kong æ¥æ”¶å®Œä¸Šæ¸¸æœåŠ¡è¿”å›çš„ Header å­—æ®µåæ‰§è¡Œã€‚

```lua
      local upstream_status_header = constants.HEADERS.UPSTREAM_STATUS
      if singletons.configuration.enabled_headers[upstream_status_header] then
        header[upstream_status_header] = tonumber(sub(var.upstream_status or "", -3))
        if not header[upstream_status_header] then
          log(ERR, "failed to set ", upstream_status_header, " header")
        end
      end

      local hash_cookie = ctx.balancer_data.hash_cookie
      if not hash_cookie then
        return
      end

      local cookie = ck:new()
      local ok, err = cookie:set(hash_cookie)
```

`runloop.header_filter.before` ä¸­åœ¨è¿”å›ç»“æœçš„ header é‡ŒåŠ å…¥èŠ‚ç‚¹çŠ¶æ€ï¼Œä»¥åŠåˆ¤æ–­æ˜¯å¦éœ€è¦åŠ å…¥è´Ÿè½½å‡è¡¡å™¨ä¸€è‡´æ€§ç­–ç•¥çš„ Cookieã€‚

### 8.6. body_filter_by_lua é˜¶æ®µ

æ­¤é˜¶æ®µåœ¨æ¥æ”¶ä¸Šæ¸¸æœåŠ¡è¿”å›çš„ Body æ•°æ®æ—¶æ‰§è¡Œï¼Œæ ¹æ®æ•°æ®å¤§å°åˆ’åˆ† chunksï¼Œæ­¤é˜¶æ®µä¼šè¢«æ‰§è¡Œå¤šæ¬¡ã€‚

åœ¨ Openresty çš„ç”Ÿå‘½å‘¨æœŸé‡Œï¼Œ`body_filter_by_lua` ä¸­ä½¿ç”¨ `ngx.arg[1]` è¯»å– chunkï¼Œä½¿ç”¨ `ngx.arg[2]` æ ‡è®° EOFã€‚

```lua
  -- è·å–åˆ°äº†æ‰€æœ‰çš„ body
  if kong.ctx.core.response_body then
    arg[1] = kong.ctx.core.response_body
    arg[2] = true
  end

  if not arg[2] then
    return
  end

  -- è·å–åˆ°æ‰€æœ‰çš„ body å
  -- å†ç»Ÿè®¡æ‰§è¡Œæ—¶é—´
  ctx.KONG_BODY_FILTER_ENDED_AT = get_now_ms()
  ctx.KONG_BODY_FILTER_TIME = ctx.KONG_BODY_FILTER_ENDED_AT - ctx.KONG_BODY_FILTER_START

  if ctx.KONG_PROXIED then
    -- time spent receiving the response (header_filter + body_filter)
    -- we could use $upstream_response_time but we need to distinguish the waiting time
    -- from the receiving time in our logging plugins (especially ALF serializer).
    ctx.KONG_RECEIVE_TIME = ctx.KONG_BODY_FILTER_ENDED_AT - (ctx.KONG_HEADER_FILTER_START or
                                                             ctx.KONG_BALANCER_ENDED_AT or
                                                             ctx.KONG_BALANCER_START or
                                                             ctx.KONG_ACCESS_ENDED_AT)
```

### 8.7. log_by_lua é˜¶æ®µ

è°ƒç”¨ Lua çš„åƒåœ¾å›æ”¶å™¨ç»Ÿè®¡ Kong å ç”¨å†…å­˜æƒ…å†µï¼š

```lua
local update_lua_mem
do
  local pid = ngx.worker.pid
  local kong_shm = ngx.shared.kong

  local Lua_MEM_SAMPLE_RATE = 10 -- seconds
  local last = ngx.time()

  local collectgarbage = collectgarbage

  update_lua_mem = function(force)
    local time = ngx.time()

    if force or time - last >= Lua_MEM_SAMPLE_RATE then
      local count = collectgarbage("count")

      local ok, err = kong_shm:safe_set("kong:mem:" .. pid(), count)
      if not ok then
        log(ERR, "could not record Lua VM allocated memory: ", err)
      end

      last = ngx.time()
    end
  end
end
```

æ ¹æ®å“åº”ç»“æœè°ƒç”¨è´Ÿè½½å‡è¡¡å™¨è°ƒæ•´ä¸Šæ¸¸èŠ‚ç‚¹çš„æƒé‡ï¼š

```lua
      -- If response was produced by an upstream (ie, not by a Kong plugin)
      -- Report HTTP status for health checks
      local balancer_data = ctx.balancer_data
      if balancer_data and balancer_data.balancer_handle then
        local status = ngx.status
        if status == 504 then
          balancer_data.balancer.report_timeout(balancer_data.balancer_handle)
        else
          balancer_data.balancer.report_http_status(
            balancer_data.balancer_handle, status)
        end
        -- release the handle, so the balancer can update its statistics
        balancer_data.balancer_handle:release()
      end
```

## 9. Admin API

Kong Admin API å…¥å£ï¼š

```lua
function Kong.admin_content(options)
  local ctx = ngx.ctx
  if not ctx.workspace then
    ctx.workspace = kong.default_workspace
  end

  return serve_content("kong.api", options)
end
```

```lua
local function serve_content(module, options)

  -- CORS è·¨åŸŸç›¸å…³
  header["Access-Control-Allow-Origin"] = options.allow_origin or "*"

  -- å¯åŠ¨ lapis
  lapis.serve(module)
end
```

å…³äº [Lapis](https://leafo.net/lapis/)ï¼š

> Lapis is a framework for building web applications using [MoonScript](https://moonscript.org) or [Lua](https://lua.org) that runs inside of a customized version of [Nginx](https://nginx.org) called [OpenResty](https://openresty.org).

```lua
# api/init.lua
-- åŠ è½½å›ºå®šè·¯ç”±
-- Load core routes
for _, v in ipairs({"kong", "health", "cache", "config", "clustering"}) do
  local routes = require("kong.api.routes." .. v)
  api_helpers.attach_routes(app, routes)
end

  local routes = {}

  -- DAO Routes
  for _, dao in pairs(singletons.db.daos) do
    if dao.schema.generate_admin_api ~= false and not dao.schema.legacy then
      routes = Endpoints.new(dao.schema, routes)
    end
  end
```

åˆå§‹åŒ–æ„å»ºè·¯ç”±ï¼š

```lua
# api/endpoints.lua
-- åˆ›å»ºåŸºç¡€è·¯ç”±
-- Generates admin api endpoint functions
--
-- Examples:
--
-- /routes
-- /routes/:routes
-- /routes/:routes/service
-- /services/:services/routes
--
-- and
--
-- /services
-- /services/:services
-- /services/:services/routes/:routes
local function generate_endpoints(schema, endpoints)
  -- list è·¯ç”±
  -- e.g. /routes
  generate_collection_endpoints(endpoints, schema)

  -- å•ä½“è·¯ç”±
  -- e.g. /routes/:routes
  generate_entity_endpoints(endpoints, schema)

  -- åˆ¤æ–­æ˜¯å¦æœ‰å…³è”å¯¹è±¡
  -- ä¾‹å¦‚ route å…³è” services
  for foreign_field_name, foreign_field in schema:each_field() do
    -- å¤–é”®
    if foreign_field.type == "foreign" and not foreign_field.schema.legacy then
      -- e.g. /routes/:routes/service
      generate_entity_endpoints(endpoints, schema, foreign_field.schema, foreign_field_name, true)

      -- e.g. /services/:services/routes
      generate_collection_endpoints(endpoints, schema, foreign_field.schema, foreign_field_name)

      -- e.g. /services/:services/routes/:routes
      generate_entity_endpoints(endpoints, foreign_field.schema, schema, foreign_field_name)
    end
  end

  return endpoints
end

-- Generates admin api collection endpoint functions
--
-- Examples:
--
-- /routes
-- /services/:services/routes
--
-- and
--
-- /services
local function generate_collection_endpoints(endpoints, schema, foreign_schema, foreign_field_name)
  local collection_path

  -- å¤–é”®å…³è”
  if foreign_schema then
    collection_path = fmt("/%s/:%s/%s", foreign_schema.admin_api_name or
                                        foreign_schema.name,
                                        foreign_schema.name,
                                        schema.admin_api_nested_name or
                                        schema.admin_api_name or
                                        schema.name)

  else
    -- æ²¡æœ‰å¤–é”®å…³è”
    collection_path = fmt("/%s", schema.admin_api_name or
                                 schema.name)
  end

  endpoints[collection_path] = {
    schema  = schema,
    methods = {
      --OPTIONS = method_not_allowed,
      --HEAD    = method_not_allowed,
      GET     = get_collection_endpoint(schema, foreign_schema, foreign_field_name),
      POST    = post_collection_endpoint(schema, foreign_schema, foreign_field_name),
      --PUT     = method_not_allowed,
      --PATCH   = method_not_allowed,
      --DELETE  = method_not_allowed,
    },
  }
end
```

åªå…³æ³¨ POST è¯·æ±‚å¤„ç†çš„éƒ¨åˆ†ï¼š

```lua
local function post_collection_endpoint(schema, foreign_schema, foreign_field_name, method)
  return function(self, db, helpers, post_process)
    if foreign_schema then
      local foreign_entity, _, err_t = select_entity(self, db, foreign_schema)
      if err_t then
        return handle_error(err_t)
      end

      if not foreign_entity then
        return not_found()
      end

      self.args.post[foreign_field_name] = foreign_schema:extract_pk_values(foreign_entity)
    end

    -- å¤„ç†è¯·æ±‚ï¼Œå‚æ•°æ ¡éªŒï¼Œæ’å…¥æ•°æ®
    local entity, _, err_t = insert_entity(self, db, schema, method)
    if err_t then
      return handle_error(err_t)
    end

    -- å›è°ƒå‡½æ•°
    if post_process then
      entity, _, err_t = post_process(entity)
      if err_t then
        return handle_error(err_t)
      end
    end

    return created(entity)
  end
end
```

Admin API ä»…ä»…æ˜¯ä¸€å±‚ API å°è£…ï¼Œä¸è´Ÿè´£èƒŒåçš„äº‹ä»¶å¤„ç†å’Œæ•°æ®åŒæ­¥ï¼ŒèƒŒåçš„äº‹ä»¶å¤„ç†åœ¨æ–‡ç« äº‹ä»¶å¤„ç†éƒ¨åˆ†é˜è¿°è¿‡äº†ã€‚

## 10. æ’ä»¶å¼€å‘

ç®€å•ä»‹ç»ä¸€ä¸‹æ’ä»¶å¼€å‘èƒ½ç”¨ä¸Šçš„ä¸€äº›å° Trickã€‚

### 10.1. å¤šå±‚ Schema åµŒå¥—

çœ‹ç€å¾ˆæ¶å¿ƒå§ï¼Œä½†è¿™æ˜¯å¤šå±‚ Schema åµŒå¥—çš„æ ·å­ã€‚

```lua
local schema = {
    name = plugin_name,
    fields = {
        { consumer = typedefs.no_consumer },
        { protocols = typedefs.protocols_http },
        { config = {
          type = "record",
          fields = { {
            rules = {
              type = "array",
              elements = {
                type = "record",
                fields = { {
                  match = {
                    type = "array",
                    elements = {
                      type = "record",
                      fields = {
                        { vars = { type = "array", elements = {
                            type = "array",
                            elements = { type = "string" }
                        } } }
                      }
                    }
                  }
                } }
              }
            }
          } },
        } }
    }
}
```

### 10.2. è‡ªå®šä¹‰ Schema æ ¡éªŒå™¨

```lua
local expr = require("resty.expr.v1")

local schema_validator = function(conf)
    if conf.rules then
        for _, rule in ipairs(conf.rules) do
            if rule.match and type(rule.match) == "table" then
                for _, m in pairs(rule.match) do
                    local ok, err = expr.new(m.vars)
                    if not ok then
                        return false, "failed to validate the 'vars' expression: " .. err
                    end
                end
            end
        end
    end

    return true
end
```

### 10.3. æ—¥å¿—æ‰“å° Table

```lua
kong.log.inspect.on()
kong.log.debug("Lua table: ", t)
```

### 10.4. è‡ªå®šä¹‰æ—¥å¿—è¾“å‡º

2.3.0 ç‰ˆæœ¬ä»¥ä¸Šå¯ç”¨ã€‚

```lua
local entry = {
    entries = ctx.log_entries,
    id = self.transaction_id,
    action = action_name,
}

kong.log.set_serialize_value("waf", entry)
```
